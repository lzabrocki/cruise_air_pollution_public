---
title: "Analyzing Results - Entering Cruise Experiment"
description: |
  Comparing hours with entering cruise traffic to hours without. Adjusting for calendar and weather indicators.
author:
  - name: Marie-Abèle Bind 
    url: https://scholar.harvard.edu/marie-abele
    affiliation: Biostatistics Center, Massachusetts General Hospital
    affiliation_url: https://biostatistics.massgeneral.org/faculty/marie-abele-bind-phd/
  - name: Marion Leroutier 
    url: https://www.parisschoolofeconomics.eu/en/leroutier-marion/work-in-progress/
    affiliation: Misum, Stockholm School of Economics
    affiliation_url: https://www.hhs.se/en/persons/l/leroutier-marion/
  - name: Léo Zabrocki 
    url: https://lzabrocki.github.io/
    affiliation: Paris School of Economics
    affiliation_url: https://www.parisschoolofeconomics.eu/fr/zabrocki-leo/
date: "`r Sys.Date()`"
output: 
    distill::distill_article:
      keep_md: true
      toc: true
      toc_depth: 2
---

<style>
body {
text-align: justify}
</style>

In this document, we take great care providing all steps and R codes required to analyze the effects of entering cruise traffic on air pollutants. We compare hours where:

* treated units are hours with positive entering cruise traffic in t.
* control units are hours without entering cruise traffic in t.

We adjust for calendar calendar indicator and weather confouding factors.

**Should you have any questions, need help to reproduce the analysis or find coding errors, please do not hesitate to contact us at leo.zabrocki@psemail.eu and marion.leroutier@psemail.eu.**

# Required Packages

To reproduce exactly the `6_script_analyzing_results.html` document, we first need to have installed:

* the [R](https://www.r-project.org/) programming language 
* [RStudio](https://rstudio.com/), an integrated development environment for R, which will allow you to knit the `6_script_analyzing_results.Rmd` file and interact with the R code chunks
* the [R Markdown](https://rmarkdown.rstudio.com/) package
* and the [Distill](https://rstudio.github.io/distill/) package which provides the template for this document. 

Once everything is set up, we have to load the following packages:

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# load required packages
library(knitr) # for creating the R Markdown document
library(here) # for files paths organization
library(tidyverse) # for data manipulation and visualization
library(retrodesign) # for computing power, type M and S errors
library(Cairo) # for printing customed police of graphs
```

We finally load our customed `ggplot2` theme for graphs:

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# load ggplot customed theme
source(here::here("2.scripts", "4.custom_ggplot2_theme", "script_custom_ggplot_theme.R"))
````

The theme is based on the fantastic [hrbrthemes](https://hrbrmstr.github.io/hrbrthemes/index.html) package. If you do not want to use this theme or are unable to install it because of fonts issues, you can use the `theme_bw()` already included in the `ggplot2` package.

# Preparing the Data

We load the matching and matched data and bind them together:

```{R, echo = TRUE}
# load matched data
data_matched <- readRDS(here::here("1.data", "2.data_for_analysis", "1.matched_data", "1.experiments_cruise", "1.experiment_entry_cruise", "matched_data_entry_cruise.RDS"))
```

# Distribution of the Pair Differences in Concentration between Treated and Control units for each Pollutant

## Computing Pairs Differences in Pollutant Concentrations

We first compute the differences in a pollutant's concentration for each pair over time:

```{R, echo=TRUE}
data_matched_wide <- data_matched %>%
    mutate(is_treated = ifelse(is_treated == TRUE, "treated", "control")) %>%
  select(is_treated, pair_number, contains("no2_l"), contains("no2_sl"), contains("o3"), contains("pm10_l"), contains("pm10_sl"),contains("pm25"), contains("so2")) %>%
  pivot_longer(cols = -c(pair_number, is_treated), names_to = "variable", values_to = "concentration") %>%
  mutate(pollutant = NA %>%
           ifelse(str_detect(variable, "no2_l"), "NO2 Longchamp",.) %>%
           ifelse(str_detect(variable, "no2_sl"), "NO2 Saint-Louis",.) %>%
           ifelse(str_detect(variable, "o3"), "O3 Longchamp",.) %>%
           ifelse(str_detect(variable, "pm10_l"), "PM10 Longchamp",.) %>%
           ifelse(str_detect(variable, "pm10_sl"), "PM10 Saint-Louis",.) %>%
           ifelse(str_detect(variable, "pm25"), "PM2.5 Longchamp",.) %>%
           ifelse(str_detect(variable, "so2"), "SO2 Lonchamp",.)) %>%
  mutate(time = 0 %>%
           ifelse(str_detect(variable, "lag_1"), -1, .) %>%
           ifelse(str_detect(variable, "lag_2"), -2, .) %>%
           ifelse(str_detect(variable, "lag_3"), -3, .) %>%
           ifelse(str_detect(variable, "lead_1"), 1, .) %>%
           ifelse(str_detect(variable, "lead_2"), 2, .) %>%
           ifelse(str_detect(variable, "lead_3"), 3, .)) %>%
  select(-variable) %>%
  select(pair_number, is_treated, pollutant, time, concentration) %>% 
  pivot_wider(names_from = is_treated, values_from = concentration)

data_pair_difference_pollutant <- data_matched_wide %>%
  mutate(difference = treated-control) %>%
  select(-c(treated, control))
````

## Pairs Differences in NO2 Concentrations

Boxplots for NO2:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# create the graph for no2
graph_boxplot_difference_pollutant_no2 <- data_pair_difference_pollutant %>%
  filter(str_detect(pollutant, "NO2")) %>%
  ggplot(., aes(x = as.factor(time), y = difference)) +
  geom_boxplot(colour = "deepskyblue3") +
  facet_wrap(~ pollutant) +
  ggtitle("Distribution of Pair Difference in Concentration") +
  ylab("Pair Difference in \nConcentration (µg/m3)") + xlab("Hour") +
  custom_theme

# display the graph
graph_boxplot_difference_pollutant_no2

# save the graph
graph_boxplot_difference_pollutant_no2 <- graph_boxplot_difference_pollutant_no2 +
  theme(plot.title = element_blank())

ggsave(graph_boxplot_difference_pollutant_no2, filename = here::here("3.outputs", "1.figures", "2.experiments_cruise", "1.experiment_entry_cruise", "2.matching_results", "graph_boxplot_difference_pollutant_no2.pdf"), 
       width = 40, height = 18, units = "cm", device = cairo_pdf)
````

## Pairs Differences in O3 Concentrations

Boxplots for O3:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# create the graph for o3
graph_boxplot_difference_pollutant_o3 <- data_pair_difference_pollutant %>%
  filter(str_detect(pollutant, "O3")) %>%
  ggplot(., aes(x = as.factor(time), y = difference)) +
  geom_boxplot(colour = "deepskyblue3") +
  ggtitle("Distribution of Pair Difference in Concentration") +
  ylab("Pair Difference in \nConcentration (µg/m3)") + xlab("Hour") +
  custom_theme

# display the graph
graph_boxplot_difference_pollutant_o3

# save the graph
graph_boxplot_difference_pollutant_o3 <- graph_boxplot_difference_pollutant_o3 +
  theme(plot.title = element_blank())

ggsave(graph_boxplot_difference_pollutant_o3, filename = here::here("3.outputs", "1.figures", "2.experiments_cruise", "1.experiment_entry_cruise", "2.matching_results", "graph_boxplot_difference_pollutant_o3.pdf"), 
       width = 30, height = 15, units = "cm", device = cairo_pdf)
````

## Pairs Differences in PM10 Concentrations

Boxplots for PM10:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# create the graph for pm10
graph_boxplot_difference_pollutant_pm10 <- data_pair_difference_pollutant %>%
  filter(str_detect(pollutant, "PM10")) %>%
  ggplot(., aes(x = as.factor(time), y = difference)) +
  geom_boxplot(colour = "deepskyblue3") +
  facet_wrap(~ pollutant) +
  ggtitle("Distribution of Pair Difference in Concentration") +
  ylab("Pair Difference in \nConcentration (µg/m3)") + xlab("Hour") +
  custom_theme

# display the graph
graph_boxplot_difference_pollutant_pm10

# save the graph
graph_boxplot_difference_pollutant_pm10 <- graph_boxplot_difference_pollutant_pm10 +
  theme(plot.title = element_blank())

ggsave(graph_boxplot_difference_pollutant_pm10, filename = here::here("3.outputs", "1.figures", "2.experiments_cruise", "1.experiment_entry_cruise", "2.matching_results", "graph_boxplot_difference_pollutant_pm10.pdf"), 
       width = 40, height = 18, units = "cm", device = cairo_pdf)
````

## Pairs Differences in PM2.5 Concentrations

Boxplots for PM2.5:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# create the graph for pm2.5
graph_boxplot_difference_pollutant_pm25 <- data_pair_difference_pollutant %>%
  filter(str_detect(pollutant, "PM2.5")) %>%
  ggplot(., aes(x = as.factor(time), y = difference)) +
  geom_boxplot(colour = "deepskyblue3") +
  ggtitle("Distribution of Pair Difference in Concentration") +
  ylab("Pair Difference in \nConcentration (µg/m3)") + xlab("Hour") +
  custom_theme

# display the graph
graph_boxplot_difference_pollutant_pm25

# save the graph
graph_boxplot_difference_pollutant_pm25 <- graph_boxplot_difference_pollutant_pm25 +
  theme(plot.title = element_blank())

ggsave(graph_boxplot_difference_pollutant_pm25, filename = here::here("3.outputs", "1.figures", "2.experiments_cruise", "1.experiment_entry_cruise", "2.matching_results", "graph_boxplot_difference_pollutant_pm25.pdf"), 
       width = 30, height = 15, units = "cm", device = cairo_pdf)
````

## Pairs Differences in SO2 Concentrations

Boxplots for SO2:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# create the graph for so2
graph_boxplot_difference_pollutant_so2 <- data_pair_difference_pollutant %>%
  filter(str_detect(pollutant, "SO2")) %>%
  ggplot(., aes(x = as.factor(time), y = difference)) +
  geom_boxplot(colour = "deepskyblue3") +
  ggtitle("Distribution of Pair Difference in Concentration") +
  ylab("Pair Difference in \nConcentration (µg/m3)") + xlab("Hour") +
  custom_theme

# display the graph
graph_boxplot_difference_pollutant_so2

# save the graph
graph_boxplot_difference_pollutant_so2 <- graph_boxplot_difference_pollutant_so2 +
  theme(plot.title = element_blank())

ggsave(graph_boxplot_difference_pollutant_so2, filename = here::here("3.outputs", "1.figures", "2.experiments_cruise", "1.experiment_entry_cruise", "2.matching_results", "graph_boxplot_difference_pollutant_so2.pdf"), 
       width = 30, height = 15, units = "cm", device = cairo_pdf)
````

# Testing the Sharp Null Hypothesis

We test the sharp null hypothesis of no effect for any units. We first create a dataset where we nest the pair differences by pollutant and time. We also compute the observed test statistic which is the observed average of pair differences:

```{R, echo=TRUE}
# nest the data by pollutant and time
ri_data_sharp_null <- data_pair_difference_pollutant   %>%
  select(pollutant, time, difference) %>%
  group_by(pollutant, time) %>%
  mutate(observed_mean_difference = mean(difference)) %>%
  group_by(pollutant, time, observed_mean_difference) %>%
  summarise(data_difference = list(difference))
````

We then create a function to compute the randomization distribution of the test statistic:

```{R, echo=TRUE}
# randomization distribution function
# this function takes the vector of pair differences
# and then compute the average pair difference according 
# to the permuted treatment assignment
function_randomization_distribution <- function(data_difference) {
  randomization_distribution = NULL
  n_columns = dim(permutations_matrix)[2]
  for (i in 1:n_columns) {
    randomization_distribution[i] =  sum(data_difference * permutations_matrix[, i]) / number_pairs
  }
  return(randomization_distribution)
}
````

We store the number of pairs and the number of simulations we want to run:

```{R, echo=TRUE}
# define number of pairs in the experiment
number_pairs <- nrow(data_matched)/2

# define number of simulations
number_simulations <- 100000
````

We compute the permutations matrix:

```{R, echo=TRUE}
# set the seed
set.seed(42)

# compute the permutations matrix
permutations_matrix <- matrix(rbinom(number_pairs*number_simulations, 1,.5)*2-1, nrow = number_pairs, ncol = number_simulations)
````

For each pollutant and time, we compute the randomization distribution of the test statistic using 100,000 iterations. It took us 46 seconds to run this code chunck on our basic local computer:

```{R, echo=TRUE}
# compute the test statistic distribution
ri_data_sharp_null <- ri_data_sharp_null %>%
  mutate(randomization_distribution = map(data_difference, ~ function_randomization_distribution(.)))
````

Using the observed value of the test statistic and its randomization distribution, we compute the two-sided *p*-values:

```{R, echo=TRUE}
# function to compute the upper one-sided p-value
function_fisher_upper_p_value <- function(observed_mean_difference, randomization_distribution){
  sum(randomization_distribution >= observed_mean_difference)/number_simulations
}

# function compute the lower one-sided p-value
function_fisher_lower_p_value <- function(observed_mean_difference, randomization_distribution){
  sum(randomization_distribution <= observed_mean_difference)/number_simulations
}

# compute the lower and upper one-sided p-values
ri_data_sharp_null <- ri_data_sharp_null %>%
  mutate(p_value_upper = map2_dbl(observed_mean_difference, randomization_distribution, ~ function_fisher_upper_p_value(.x, .y)),
         p_value_lower = map2_dbl(observed_mean_difference, randomization_distribution, ~ function_fisher_lower_p_value(.x, .y)))

# compute the two-sided p-value using rosenbaum (2010) procedure
ri_data_sharp_null <- ri_data_sharp_null %>%
  rowwise() %>%
  mutate(two_sided_p_value = min(c(p_value_upper, p_value_lower))*2) %>%
  mutate(two_sided_p_value = min(two_sided_p_value, 1)) %>%
  select(pollutant, time, observed_mean_difference, two_sided_p_value) %>%
  ungroup()
````


We plot below the two-sided p-values for the sharp null hypothesis for each pollutant:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# make the graph
graph_p_values <- ri_data_sharp_null %>%
  ggplot(., aes(x = as.factor(time), y = two_sided_p_value)) +
  geom_segment(aes(x = as.factor(time), xend = as.factor(time), y = 0, yend = two_sided_p_value)) +
  geom_point(shape = 21, size = 8, colour = "black", fill = "deepskyblue3") +
  facet_wrap(~ pollutant, ncol = 4) +
  xlab("Hour") + ylab("Two-Sided P-Value") +
  custom_theme +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # axis texts
    axis.text.x = element_text(size=20),
    axis.text.y = element_text(size=20),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"))
  
# display the graph
graph_p_values

# save the graph
ggsave(graph_p_values, filename = here::here("3.outputs", "1.figures", "2.experiments_cruise", "1.experiment_entry_cruise", "2.matching_results", "graph_p_values.pdf"), 
       width = 60, height = 25, units = "cm", device = cairo_pdf)
```

We display below the table of Fisher p-values:

```{r, echo = FALSE, layout="l-body-outset"}
ri_data_sharp_null %>%
  select(pollutant, time, observed_mean_difference, two_sided_p_value) %>%
  mutate(observed_mean_difference = round(observed_mean_difference, 1)) %>%
  rename("Pollutant" = pollutant, "Time" = time, "Observed Value of the Test Statistic" = observed_mean_difference, "Two-Sided P-Values"= two_sided_p_value) %>%
  rmarkdown::paged_table(.)
````

# Computing Fisherian intervals

To quickly compute 95% Fisherian intervals, we run the procedure on an Amazon Web Services virtual computer (EC2 t3.2xlarge). It took about 38 minutes for the code to run. It can be found in the `script_aws_fisherian_intervals.R` file. We explain below how we proceed. We first create a nested dataset with the pair differences for each pollutant and hour. We also add the set of hypothetical constant effects.

```{R, eval = FALSE}
# create a nested dataframe with 
# the set of constant treatment effect sizes
# and the vector of observed pair differences
ri_data_fi <- data_pair_difference_pollutant %>%
  select(pollutant, time, difference) %>%
  group_by(pollutant, time) %>%
  summarise(data_difference = list(difference)) %>%
  group_by(pollutant, time, data_difference) %>%
  expand(effect = seq(from = -10, to = 10, by = 0.1)) %>%
  ungroup()
````
 
We then substract for each pair difference the hypothetical constant effect:

```{R, eval = FALSE}
# function to get the observed statistic
adjusted_pair_difference_function <- function(pair_differences, effect){
  adjusted_pair_difference <- pair_differences-effect
  return(adjusted_pair_difference)
} 

# compute the adjusted pair differences
ri_data_fi <- ri_data_fi %>%
  mutate(data_adjusted_pair_difference = map2(data_difference, effect, ~ adjusted_pair_difference_function(.x, .y)))
````

We compute the observed mean of adjusted pair differences:

```{R, eval = FALSE}
# compute the observed mean of adjusted pair differences
ri_data_fi <- ri_data_fi %>%
  mutate(observed_mean_difference = map(data_adjusted_pair_difference, ~ mean(.))) %>%
  unnest(cols = c(observed_mean_difference)) %>%
  select(-data_difference) %>%
  ungroup()
````  

We use the same `function_randomization_distribution` to compute the randomization distribution of the test statistic and run 100,000 iterations for each pollutant-hour observation:

```{R, eval = FALSE}
# define number of pairs in the experiment
number_pairs <- nrow(data_matched)/2

# define number of simulations
number_simulations <- 100000

# compute the permutations matrix
permutations_matrix <- matrix(rbinom(number_pairs*number_simulations, 1,.5)*2-1, nrow = number_pairs, ncol = number_simulations)

# randomization distribution function
# this function takes the vector of pair differences
# and then compute the average pair difference according 
# to the permuted treatment assignment
function_randomization_distribution <- function(data_difference) {
  randomization_distribution = NULL
  n_columns = dim(permutations_matrix)[2]
  for (i in 1:n_columns) {
    randomization_distribution[i] =  sum(data_difference * permutations_matrix[, i]) / number_pairs
  }
  return(randomization_distribution)
}
````  

We run the function:

```{R, eval = FALSE}
# compute the test statistic distribution
ri_data_fi <- ri_data_fi %>%
  mutate(randomization_distribution = map(data_adjusted_pair_difference, ~ function_randomization_distribution(.)))
````  

We compute the lower and upper *p*-values functions. From these functions, we retrieve the lower and upper bound of the 95% Fisherian intervals:

```{R, eval = FALSE}
# define the p-values functions
function_fisher_upper_p_value <- function(observed_mean_difference, randomization_distribution){
  sum(randomization_distribution >= observed_mean_difference)/number_simulations
}

function_fisher_lower_p_value <- function(observed_mean_difference, randomization_distribution){
  sum(randomization_distribution <= observed_mean_difference)/number_simulations
}

# compute the lower and upper one-sided p-values
ri_data_fi <- ri_data_fi %>%
  mutate(p_value_upper = map2_dbl(observed_mean_difference, randomization_distribution, ~ function_fisher_upper_p_value(.x, .y)),
         p_value_lower = map2_dbl(observed_mean_difference, randomization_distribution, ~ function_fisher_lower_p_value(.x, .y)))

# retrieve the constant effects with the p-values equal or the closest to 0.025
ri_data_fi <- ri_data_fi %>%
  mutate(p_value_upper = abs(p_value_upper - 0.025),
         p_value_lower = abs(p_value_lower - 0.025)) %>%
  group_by(pollutant, time) %>%
  filter(p_value_upper == min(p_value_upper) | p_value_lower == min(p_value_lower)) %>%
# in case two effect sizes have a p-value equal to 0.025, we take the effect size
# that make the Fisherian interval wider to be conservative
  summarise(lower_fi = min(effect),
            upper_fi = max(effect))
````  

We finally compute the point estimates of the Fisherian intervals which we define as the observed average of pair differences:

```{R, eval = FALSE}
# compute observed average of pair differences
ri_data_fi_point_estimate <- data_pair_difference_pollutant   %>%
  select(pollutant, time, difference) %>%
  group_by(pollutant, time) %>%
  mutate(observed_mean_difference = mean(difference)) %>%
  ungroup()
````  

We merge the point estimates data with the Fisherian intervals data:

```{R, eval = FALSE}
# merge ri_data_fi_point_estimate with ri_data_fi
ri_data_fi_final <- left_join(ri_data_fi, ri_data_fi_point_estimate, by = c("pollutant", "time"))
````  

We plot below the 95% Fisherian intervals:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# open the data on fisherian intervals
ri_data_fi_final <- readRDS(here::here("1.data", "2.data_for_analysis", "1.matched_data", "1.experiments_cruise", "1.experiment_entry_cruise", "ri_data_fisherian_intervals.rds"))

# create an indicator to alternate shading of confidence intervals
ri_data_fi_final <- ri_data_fi_final %>%
  arrange(pollutant, time) %>%
  mutate(stripe = ifelse((time %% 2) == 0, "Grey", "White")) %>%
  ungroup()

# make the graph
graph_fisherian_intervals <- ggplot(ri_data_fi_final, aes(x = as.factor(time), y = observed_mean_difference)) +
      geom_rect(aes(fill = stripe), xmin = as.numeric(as.factor(ri_data_fi_final$time))-0.42,
            xmax = as.numeric(as.factor(ri_data_fi_final$time))+0.42, ymin = -Inf, ymax=Inf, color = NA, alpha = 0.4) +
  geom_hline(yintercept = 0, color="black") +
  geom_vline(xintercept = "0", color = "black") +
  geom_pointrange(aes(x = as.factor(time), y = observed_mean_difference, ymin = lower_fi ,
                      ymax = upper_fi), colour="deepskyblue3", lwd = 0.8) +
  facet_wrap(~ pollutant, scales = "free_y", ncol = 4) +
  scale_fill_manual(values = c('gray96', NA)) +
  guides(fill = FALSE) +
  ylab("Constant-Additive Increase \nin Concentrations (µg/m³)") + xlab("Hour") +
  custom_theme +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"))

# print the graph
graph_fisherian_intervals

# save the graph
ggsave(graph_fisherian_intervals, filename = here::here("3.outputs", "1.figures", "2.experiments_cruise", "1.experiment_entry_cruise", "2.matching_results", "graph_fisherian_intervals.pdf"), width = 70, height = 30, units = "cm", device = cairo_pdf)
```

We display below the table with the 95% fiducial intervals and the point estimates:

```{r, echo = FALSE, layout="l-body-outset"}
ri_data_fi_final %>%
  select(pollutant, time, observed_mean_difference, lower_fi, upper_fi) %>%
  mutate(observed_mean_difference = round(observed_mean_difference, 1)) %>%
  rename("Pollutant" = pollutant, "Time" = time, "Point Estimate" = observed_mean_difference, "Lower Bound of the 95% Fisherian Interval" = lower_fi, "Upper Bound of the 95% Fisherian Interval" = upper_fi) %>%
  rmarkdown::paged_table(.)
````

# Checking the Sensivity of Results

In this section, we carry out four investigations:

* We check how our results are sensitive to outliers by computing 95% fiducial intervals based on the Wilcoxon's signed rank test statistic.
* As we imputed the missing pollutant concentrations, we also want to see how our results might for the non-missing outcomes. We compute 95% fiducial intervals based on the Wilcoxon's signed rank test statistic.
* We compute confidence intervals for the average treatment effect using Neyman's approach.
* We explore how our study could suffer from type S and M errors.

### Outliers

To gauge how sensitive our results are to outliers, we use a Wilcoxon signed rank test statistic and compute 95% fiducial intervals using the `wilcox.test()` function.

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# carry out the wilcox.test 
data_rank_ci <- data_pair_difference_pollutant %>%
  select(- pair_number) %>%
  group_by(pollutant, time) %>%
  nest() %>%
  mutate(effect = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$estimate),
         lower_ci = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$conf.int[1]),
         upper_ci = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$conf.int[2])) %>%
  unnest(cols = c(effect, lower_ci, upper_ci)) %>%
  mutate(data = "Wilcoxon Rank Test Statistic")

# bind ri_data_fi_final with data_rank_ci
data_ci <- ri_data_fi_final %>%
  rename(effect = observed_mean_difference, lower_ci = lower_fi, upper_ci = upper_fi) %>%
  mutate(data = "Average Pair Difference Test Statistic") %>%
  bind_rows(., data_rank_ci)

# create an indicator to alternate shading of confidence intervals
data_ci <- data_ci %>%
  arrange(pollutant, time) %>%
  mutate(stripe = ifelse((time %% 2) == 0, "Grey", "White")) %>%
  ungroup()

# make the graph
graph_ri_ci_wilcoxon <- ggplot(data_ci, aes(x = as.factor(time), y = effect, ymin = lower_ci,
                        ymax = upper_ci, colour = data, shape = data)) +
  geom_rect(aes(fill = stripe), xmin = as.numeric(as.factor(data_ci$time))-0.42,
            xmax = as.numeric(as.factor(data_ci$time))+0.42, ymin = -Inf, ymax=Inf, color = NA, alpha = 0.4) +
  geom_hline(yintercept = 0, color="black") +
  geom_pointrange(position = position_dodge(width = 1), size = 0.8, fatten = 2) +
  scale_shape_manual(name = "Test Statistic:", values = c(16, 17)) +
  scale_color_manual(name = "Test Statistic:", values = c("coral", "deepskyblue3")) +
  facet_wrap(~ pollutant, scales = "free_y", ncol = 4) +
  scale_fill_manual(values = c('gray92', NA)) +
  guides(fill = FALSE) +
  ylab("Constant-Additive Increase \nin Concentrations (µg/m³)") + xlab("Hour") +
  custom_theme +
  theme(legend.position = "top", legend.justification = "left", legend.direction = "horizontal") +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # axis texts
    axis.text.x = element_text(size=20),
    axis.text.y = element_text(size=20),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"),
    # legend parameters
    legend.position = "top", legend.justification = "left", legend.direction = "horizontal",
    legend.title = element_text(size=36, face = "bold"),
    legend.text = element_text(size=28))

# print the graph
graph_ri_ci_wilcoxon

# save the graph
ggsave(graph_ri_ci_wilcoxon, filename = here::here("3.outputs", "1.figures", "2.experiments_cruise", "1.experiment_entry_cruise", "2.matching_results", "graph_ri_ci_wilcoxon.pdf"), width = 70, height = 30, units = "cm", device = cairo_pdf)
```

### Missing Outcomes

We load non-imputed air pollution data and compute for each pollutant the 0-6 daily lags and leads:

```{R, echo = TRUE}
# load marseille raw air pollution data
data_marseille_raw_pollutants <- readRDS(here::here("1.data", "1.raw_data", "2.pollution_data", "marseille", "raw_marseille_hourly_pollutants_2008_2018_data.rds")) %>%
  rename_at(vars(-date), function(x) paste0("raw_", x))

# we first define data_marseille_raw_pollutants_leads and data_marseille_raw_pollutants_lags
# to store leads and lags

data_marseille_raw_pollutants_leads <- data_marseille_raw_pollutants
data_marseille_raw_pollutants_lags <- data_marseille_raw_pollutants

#
# create leads
# 

# create a list to store dataframe of leads
leads_list <- vector(mode = "list", length = 3)
names(leads_list) <- c(1:3) 

# create the leads
for(i in 1:3){
  leads_list[[i]] <- data_marseille_raw_pollutants_leads %>%
    mutate_at(vars(-date), ~  lead(., n = i, order_by = date)) %>%
    rename_at(vars(-date),function(x) paste0(x,"_lead_", i))
}

# merge the dataframes of leads
data_leads <- leads_list %>%
  reduce(left_join, by = "date")

# merge the leads with the data_marseille_raw_pollutants_leads
data_marseille_raw_pollutants_leads <- left_join(data_marseille_raw_pollutants_leads, data_leads, by = "date") %>%
  select(-c(raw_mean_no2_l:raw_mean_pm10_sl))

#
# create lags
# 

# create a list to store dataframe of lags
lags_list <- vector(mode = "list", length = 3)
names(lags_list) <- c(1:3) 

# create the lags
for(i in 1:3){
  lags_list[[i]] <- data_marseille_raw_pollutants_lags %>%
    mutate_at(vars(-date), ~  lag(., n = i, order_by = date)) %>%
    rename_at(vars(-date),function(x) paste0(x,"_lag_", i))
}

# merge the dataframes of lags
data_lags <- lags_list %>%
  reduce(left_join, by = "date")

# merge the lags with the initial data_marseille_raw_pollutants_lags
data_marseille_raw_pollutants_lags <- left_join(data_marseille_raw_pollutants_lags, data_lags, by = "date")

#
# merge data_marseille_raw_pollutants_leads with data_marseille_raw_pollutants_lags
#

data_marseille_raw_pollutants <- left_join(data_marseille_raw_pollutants_lags, data_marseille_raw_pollutants_leads, by = "date")
````

We merge these data with the matched data and compute pair differences: 

```{R, echo = TRUE}
# merge with the matched data
data_matched_with_raw_pollutants <- merge(data_matched, data_marseille_raw_pollutants, by = "date")

# compute pair differences
data_matched_wide_raw_pollutants <- data_matched_with_raw_pollutants %>%
  mutate(is_treated = ifelse(is_treated == TRUE, "treated", "control")) %>%
  select(is_treated, pair_number, contains("raw_mean_no2_l"), contains("raw_mean_no2_sl"), contains("raw_mean_o3"), contains("raw_mean_pm10_l"), contains("raw_mean_pm10_sl"), contains("raw_mean_pm25"), contains("raw_mean_so2")) %>%
  pivot_longer(cols = -c(pair_number, is_treated), names_to = "variable", values_to = "concentration") %>%
  mutate(pollutant = NA %>%
           ifelse(str_detect(variable, "no2_l"), "NO2 Longchamp",.) %>%
           ifelse(str_detect(variable, "no2_sl"), "NO2 Saint-Louis",.) %>%
           ifelse(str_detect(variable, "o3"), "O3 Longchamp",.) %>%
           ifelse(str_detect(variable, "pm10_l"), "PM10 Longchamp",.) %>%
           ifelse(str_detect(variable, "pm10_sl"), "PM10 Saint-Louis",.) %>%
           ifelse(str_detect(variable, "pm25"), "PM2.5 Longchamp",.) %>%
           ifelse(str_detect(variable, "so2"), "SO2 Lonchamp",.)) %>%
  mutate(time = 0 %>%
           ifelse(str_detect(variable, "lag_1"), -1, .) %>%
           ifelse(str_detect(variable, "lag_2"), -2, .) %>%
           ifelse(str_detect(variable, "lag_3"), -3, .) %>%
           ifelse(str_detect(variable, "lead_1"), 1, .) %>%
           ifelse(str_detect(variable, "lead_2"), 2, .) %>%
           ifelse(str_detect(variable, "lead_3"), 3, .)) %>%
  select(-variable) %>%
  select(pair_number, is_treated, pollutant, time, concentration) %>% 
  pivot_wider(names_from = is_treated, values_from = concentration)

data_raw_pair_difference_pollutant <- data_matched_wide_raw_pollutants %>%
  mutate(difference = treated-control) %>%
  select(-c(treated, control)) 
```

We display below the number of missing differences by pollutant and day:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# make the graph
graph_missing_pollutants <- data_raw_pair_difference_pollutant %>%
  group_by(pollutant, time) %>%
  summarise(n_missing = sum(is.na(difference))) %>%
  ggplot(., aes(x = as.factor(time), y = n_missing)) +
  geom_segment(aes(x = as.factor(time), xend = as.factor(time), y = 0, yend = n_missing)) +
  geom_point(shape = 21, size = 4, colour = "black", fill = "deepskyblue3") +
  facet_wrap(~ pollutant) +
  xlab("Day") + ylab("Number of Pairs with Missing Concentrations") +
  custom_theme 
  
# display the graph
graph_missing_pollutants

# save the graph
ggsave(graph_missing_pollutants, filename = here::here("3.outputs", "1.figures", "2.experiments_cruise", "1.experiment_entry_cruise", "2.matching_results", "graph_missing_pollutants.pdf"), 
       width = 40, height = 20, units = "cm", device = cairo_pdf)
```

As we have `r nrow(data_matched)/2` pairs, up to 25% of the pairs can have missing pollutant concentrations. We compute below the 95% fiducial intervals for pairs without missing concentrations and compare the results to those found with the imputed dataset:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# carry out the wilcox.test 
data_raw_rank_ci <- data_raw_pair_difference_pollutant %>%
  drop_na() %>%
  select(- pair_number) %>%
  group_by(pollutant, time) %>%
  nest() %>%
  mutate(effect = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$estimate),
         lower_ci = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$conf.int[1]),
         upper_ci = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$conf.int[2])) %>%
  unnest(cols = c(effect, lower_ci, upper_ci)) %>%
  mutate(data = "Pairs without Missing Concentrations")

# bind data_rank_ci with data_raw_rank_ci
data_ci <- data_rank_ci %>%
  mutate(data = "Pairs with Imputed Pollutant Concentrations") %>%
  bind_rows(., data_raw_rank_ci)

# create an indicator to alternate shading of confidence intervals
data_ci <- data_ci %>%
  arrange(pollutant, time) %>%
  mutate(stripe = ifelse((time %% 2) == 0, "Grey", "White")) %>%
  ungroup()

# make the graph
graph_ri_ci_missing_concentration <- ggplot(data_ci, aes(x = as.factor(time), y = effect, ymin = lower_ci,
                        ymax = upper_ci, colour = data, shape = data)) +
  geom_rect(aes(fill = stripe), xmin = as.numeric(as.factor(data_ci$time))-0.42,
            xmax = as.numeric(as.factor(data_ci$time))+0.42, ymin = -Inf, ymax=Inf, color = NA, alpha = 0.4) +
  geom_hline(yintercept = 0, color="black") +
  geom_pointrange(position = position_dodge(width = 1), size = 0.8, fatten = 2) +
  scale_shape_manual(name = "Dataset:", values = c(16, 17)) +
  scale_color_manual(name = "Dataset:", values = c("coral", "deepskyblue3")) +
  facet_wrap(~ pollutant, scales = "free_y", ncol = 4) +
  scale_fill_manual(values = c('gray92', NA)) +
  guides(fill = FALSE) +
  ylab("Constant-Additive Increase \nin Concentrations (µg/m³)") + xlab("Hour") +
  custom_theme +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # axis texts
    axis.text.x = element_text(size=20),
    axis.text.y = element_text(size=20),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"),
    # legend parameters
    legend.position = "top", legend.justification = "left", legend.direction = "horizontal",
    legend.title = element_text(size=36, face = "bold"),
    legend.text = element_text(size=28))

# print the graph
graph_ri_ci_missing_concentration

# save the graph
ggsave(graph_ri_ci_missing_concentration, filename = here::here("3.outputs", "1.figures", "2.experiments_cruise", "1.experiment_entry_cruise", "2.matching_results", "graph_ri_ci_missing_concentration.pdf"), width = 70, height = 30, units = "cm", device = cairo_pdf)
``` 

### Neyman's Approach: Computing Confidence Intervals for the Average Treatment Effects

We compute confidence intervals for the average treatement using Neyman's approach. We use the formula for the standard error of pair randomized experiment found in Imbens and Rubin (2015).

```{R, echo=TRUE}
# we first compute the average treatment effects for each pollutant and hour
data_pair_mean_difference <- data_pair_difference_pollutant %>%
  group_by(pollutant, time) %>%
  summarise(mean_difference = mean(difference)) %>%
  ungroup()

# we store the number of pairs
n_pair <- nrow(data_matched)/2

# compute the standard error
data_se_neyman_pair <- left_join(data_pair_difference_pollutant, data_pair_mean_difference, by = c("pollutant", "time")) %>%
  mutate(squared_difference = (difference-mean_difference)^2) %>%
  group_by(pollutant, time) %>%
  summarise(standard_error = sqrt(1/(n_pair*(n_pair-1))*sum(squared_difference))) %>%
  select(pollutant, time, standard_error) %>%
  ungroup()

# merge the average treatment effect data witht the standard error data
data_neyman <- left_join(data_pair_mean_difference, data_se_neyman_pair, by = c("pollutant", "time")) %>%
# compute the 95% confidence intervals
  mutate(ci_lower_95 = mean_difference - 1.96*standard_error,
         ci_upper_95 = mean_difference + 1.96*standard_error)
``` 

We plot the the point estimates for the average treatment effects and their associated 95% confidence intervals:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# create an indicator to alternate shading of confidence intervals
data_neyman <- data_neyman %>%
  arrange(pollutant, time) %>%
  mutate(stripe = ifelse((time %% 2) == 0, "Grey", "White")) %>%
  ungroup()

# make the graph
graph_neyman_ci <-
  ggplot(data_neyman, aes(x = as.factor(time), y = mean_difference)) +
  geom_rect(
    aes(fill = stripe),
    xmin = as.numeric(as.factor(data_neyman$time)) - 0.42,
    xmax = as.numeric(as.factor(data_neyman$time)) + 0.42,
    ymin = -Inf,
    ymax = Inf,
    color = NA,
    alpha = 0.4
  ) +
  geom_hline(yintercept = 0, color = "black") +
  geom_vline(xintercept = "0", color = "black") +
  geom_pointrange(
    aes(
      x = as.factor(time),
      y = mean_difference,
      ymin = ci_lower_95 ,
      ymax = ci_upper_95
    ),
    colour = "deepskyblue3",
    lwd = 0.8
  ) +
  facet_wrap( ~ pollutant, scales = "free_y", ncol = 4) +
  scale_fill_manual(values = c('gray92', NA)) +
  guides(fill = FALSE) +
  ylab("Average Pair Difference \nin Concentrations (µg/m³)") + xlab("Hour") +
  custom_theme +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # axis texts
    axis.text.x = element_text(size=20),
    axis.text.y = element_text(size=20),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"),
    # legend parameters
    legend.position = "top", legend.justification = "left", legend.direction = "horizontal",
    legend.title = element_text(size=36, face = "bold"),
    legend.text = element_text(size=28))

# print the graph
graph_neyman_ci

# save the graph
ggsave(
  graph_neyman_ci,
  filename = here::here(
    "3.outputs",
    "1.figures",
    "2.experiments_cruise",
    "1.experiment_entry_cruise",
    "2.matching_results",
    "graph_ci_neyman.pdf"
  ),
  width = 70,
  height = 30,
  units = "cm",
  device = cairo_pdf
)
``` 


### Statistical Power Issues 

Our matching procedure resulted in few matched treated units: we might therefore have a low statistical power to detect the effect of cruise vessels on air pollutant concentrations. Even more worrying is our higher chance to suffer from type-S an type-M errors. While we do not know what the true effect of cruise on air pollutants is, we can explore our statistical power and our probability to make types S and M errors using a grid of plausible effect sizes. We proceed as follows:

* We take the standard error computed for the average treatment effect of cruise on NO2 concentration in *t* at Saint-Louis. 
* We set create a grid of plausible effect sizes.
* The `retrodesign` package allows us to compute the statistical power, the type-M and type-S errors associated with each effect size.

```{R, echo=TRUE}
# retrieve the standard error
standard_error <- data_neyman %>%
  filter(pollutant == "NO2 Saint-Louis" & time == 0) %>%
  pull(standard_error)

# create data on plausible effect sizes
data_type_m_s_errors <- tibble(plausible_effect = seq(from = 0.25, to = 6, by = 0.1))

# add the standard error to data_type_m_s_errors
data_type_m_s_errors <- data_type_m_s_errors %>%
  mutate(standard_error = standard_error)

# we compute power, type s and m errors
data_type_m_s_errors <- data_type_m_s_errors %>%
  mutate(power = map2(plausible_effect, standard_error, ~ retro_design(.x, .y)$power*100),
         type_m_error = map2(plausible_effect, standard_error, ~ retro_design(.x, .y)$typeM),
         type_s_error = map2(plausible_effect, standard_error, ~ retro_design(.x, .y)$typeS*100)) %>%
  unnest(c(power, type_m_error, type_s_error))
```

We plot and save the results:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# make the graph
graph_type_m_s_errors <- data_type_m_s_errors %>%
  rename(
    "Power (%)" = power,
    "Type M Error (Bias)" = type_m_error,
    "Type S Error (%)" = type_s_error
  ) %>%
  pivot_longer(
    cols = -c(plausible_effect, standard_error),
    names_to = "variable",
    values_to = "value"
  ) %>%
  ggplot(., aes(x = plausible_effect, y = value)) +
  geom_line(size = 1.3, colour = "deepskyblue3") +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
  facet_wrap( ~ variable, scales = "free") +
  xlab("Plausible Effect Sizes for an Average Increase\n in NO2 Concentrations (µg/m³)") + ylab("") +
  custom_theme


# print the graph
graph_type_m_s_errors

# save the graph
ggsave(
  graph_type_m_s_errors,
  filename = here::here(
    "3.outputs",
    "1.figures",
    "2.experiments_cruise",
    "1.experiment_entry_cruise",
    "2.matching_results",
    "graph_type_m_s_errors.pdf"
  ),
  width = 40,
  height = 15,
  units = "cm",
  device = cairo_pdf
)
```


# Regression Analysis on Matching Data

Finally, we ran a simple time-stratified regression model on the matching data to see how the results differ with those found in our matched data analysis. We only adjust for calendar indicator and weather covariates measured at time t. Again, we ran this procedure on an Amazon Web Services virtual computer (EC2 t3.2xlarge). The code we used is in the script `script_aws_regression_matching_data.R` located in the **1.experiment_entry_cruise/script_aws** folder. It takes several minutes to run.

We load the outputs of the regression model and plot the 95% confidence intervals:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# load regression outputs
data_matching_regression <- readRDS(here::here("1.data", "2.data_for_analysis", "1.matched_data", "1.experiments_cruise", "1.experiment_entry_cruise", "data_matching_regression.rds")) %>%
# compute 95% confidence intervals using the standard error
  mutate(ci_lower_95 = estimate - 1.96*std.error,
         ci_upper_95 = estimate + 1.96*std.error)

# make the graph
graph_regression_matching_data <- ggplot(data_matching_regression, aes(x = as.factor(time), y = estimate,  ymin = ci_lower_95,
                      ymax = ci_upper_95)) +
  geom_hline(yintercept = 0, color = "black") +
  geom_vline(xintercept = "0", color = "black") +
  geom_pointrange(colour="deepskyblue3", lwd = 0.8) +
  facet_wrap(~ pollutant, scales = "free_y") +
  xlab("Hour") + ylab("Average Difference \nin Concentrations (µg/m³)") +
  custom_theme +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # axis texts
    axis.text.x = element_text(size=20),
    axis.text.y = element_text(size=20),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"),
    # legend parameters
    legend.position = "top", legend.justification = "left", legend.direction = "horizontal",
    legend.title = element_text(size=36, face = "bold"),
    legend.text = element_text(size=28))


# print the graph
graph_regression_matching_data

# save the graph
ggsave(graph_regression_matching_data, filename = here::here(
    "3.outputs",
    "1.figures",
    "2.experiments_cruise",
    "1.experiment_entry_cruise",
    "2.matching_results",
    "graph_matching_regression.pdf"
  ),
  width = 70,
  height = 30,
  units = "cm",
  device = cairo_pdf
)
```

And we display below the point estimates with the 95% confidence intervals:

```{r, echo = FALSE, layout="l-body-outset"}
data_matching_regression %>%
  select(pollutant, time, estimate, ci_lower_95, ci_upper_95) %>%
  mutate_at(vars(estimate:ci_upper_95), ~ round(., 1)) %>%
  rename("Pollutant" = pollutant, "Time" = time, "Point Estimate" = estimate, "Lower Bound of the 95% Confidence Interval" = ci_lower_95, "Upper Bound of the 95% Confidence Interval" = ci_upper_95) %>%
  rmarkdown::paged_table(.)
````
















