---
title: "Toy Example for Understanding Randomization Inference"
description: |
  How to Compute Fisherian Intervals?
author:
  - name: Marie-Abèle Bind 
    url: https://scholar.harvard.edu/marie-abele
    affiliation: Biostatistics Center, Massachusetts General Hospital
    affiliation_url: https://biostatistics.massgeneral.org/faculty/marie-abele-bind-phd/
  - name: Marion Leroutier 
    url: https://www.parisschoolofeconomics.eu/en/leroutier-marion/work-in-progress/
    affiliation: Misum, Stockholm School of Economics
    affiliation_url: https://www.hhs.se/en/persons/l/leroutier-marion/
  - name: Léo Zabrocki 
    url: https://lzabrocki.github.io/
    affiliation: Paris School of Economics
    affiliation_url: https://www.parisschoolofeconomics.eu/fr/zabrocki-leo/
date: "`r Sys.Date()`"
output: 
    distill::distill_article:
      keep_md: true
      toc: true
      toc_depth: 3
---

<style>
body {
text-align: justify}
</style>

In this document, we explain with a toy example how to:

* compute a two-sided *p*-value for the test of the sharp null hypothesis of no effect.
* carry out a test inversion procedure to compute a 95% Fisherian interval.

**Should you have any questions, need help to reproduce the analysis or find coding errors, please do not hesitate to contact us at leo.zabrocki@psemail.eu and marion.leroutier@psemail.eu.**

# Required Packages

To reproduce exactly the `script_toy_example_randomization_inference.html` document, we first need to have installed:

* the [R](https://www.r-project.org/) programming language 
* [RStudio](https://rstudio.com/), an integrated development environment for R, which will allow you to knit the `script_toy_example_randomization_inference.Rmd` file and interact with the R code chunks
* the [R Markdown](https://rmarkdown.rstudio.com/) package
* and the [Distill](https://rstudio.github.io/distill/) package which provides the template for this document. 

Once everything is set up, we have to load the following packages:

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# load required packages
library(knitr) # for creating the R Markdown document
library(here) # for files paths organization
library(tidyverse) # for data manipulation and visualization
library(kableExtra) # for building nice tables
library(Cairo) # for printing customed police of graphs
```

We finally load our customed `ggplot2` theme for graphs:

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# load ggplot customed theme
source(here::here("2.scripts", "script_custom_ggplot_theme.R"))
````

The theme is based on the fantastic [hrbrthemes](https://hrbrmstr.github.io/hrbrthemes/index.html) package. If you do not want to use this theme or are unable to install it because of fonts issues, you can use the `theme_bw()` already included in the `ggplot2` package.


# Toy Example

In this toy example, we want to estimate the effect of cruise vessels docking at Marseille's port on NO$_{2}$ concentration. For simplicity, imagine that our matching procedure resulted in 10 pairs of hours with similar weather and calendar characteristics. Treated hours are hours with cruise vessels docking at the port while control hours are hours without cruise vessels. The outcome of the experiment is the hourly NO$_{2}$ measured at a station located in the city. The exposition of this toy example is inspired by those found in Paul Rosenbaum's textbook (*Design of Observational Studies*, 2019, chapter II) and Tirthankar Dasgupta and Donald B. Rubin's forthcoming textbook (*Experimental Design: A Randomization-Based Perspective*).

# Science Table

We display below the Science Table of our imaginary experiment:

* The first column **Pair** is the indicator of the pair. We represent the index of a pair by *i* which takes values from 1 to 5.
* The second column **Unit Index** shows the index *j* of a unit within the pair (*j* is equal to 1 for the first unit in the pair and to 2 for the second unit).
* The third column **W** indicates the treatment allocation. W = 1 for treated units and W = 0 for controls.
* The fourth and fifth columns are the potential outcomes of each unit and represent the NO$_{2}$ concentrations measured in $\mu g/m^{3}$. Y(W = 0) is the potential outcome when the unit does not receive the treatment and Y(W = 1) is the potential outcome when the unit is treated. As this is an artificial example, we imagine that we know for each unit the values of both potential outcomes.
* The six column $\tau$ is the unit constant causal effect. Here, the causal effect is equal to +3 $\mu g/m^{3}$.
* The last column **Y$^{obs}$** represents the potential outcome that we would observe according to the treatment allocation, that is to say $Y_{i,j} = W_{i,j}\times Y_{i,j}(1) + (1-W_{i,j})*Y_{i,j}(0)$. Here, in each pair, the first unit does not receive the treatment so that we observe Y(0) while the second unit is treated and we observe Y(1).


```{r, echo = TRUE, message = FALSE, warning = FALSE}
# load the science table
science_table <- readRDS(here::here("1.data", "science_table.RDS"))

# display the table
science_table %>%
  rename(
    Pair = pair,
    "Unit Index" = unit,
    W = w,
    "Y(0)" = y_0,
    "Y(1)" = y_1,
    "$\\tau$" = tau,
    "Y$^{obs}$" = y
  ) %>%
  kable(align = c(rep("c", 6))) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
````

# Observed Data

Researchers will not have access to the Science Table but the table below where they only have information on the pair indicator, the unit index, the treatment allocated and the observed NO$_{2}$ concentration. Our randomization inference procedure will be based only on this table.

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# create observed data
data <- science_table %>%
  select(pair, unit, w, y)

# display observed data
data %>%
  rename(Pair = pair, "Unit Index" = unit, W = w, "Y$^{obs}$" = y) %>%
  kable(align = c(rep("c", 4))) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
````

Before moving to the inference, we need to:

* know the number of unique treatment allocations. In a pair experiment, there are $2^{I}$ unique treatement allocations, with *I* is the number of pairs. In this experiment, there are 1024 unique treatment allocations. 
* define a test statistic. We will build its distribution under the sharp null hypothesis. We use the average of pair differences as a test statistic.

# Testing the Sharp Null Hypothesis of No Treatment

### Stating the Hypothesis

The sharp null hypothesis of no treatment states that $Y_{i,j}(0) = Y_{i,j}(1)$, that is to say the treatment has no effect for each unit. With this assumption, we could impute the missing Y(1) for control units and the missing Y(0) for treated units as shown in the table below :

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# display imputed observed data
data %>%
  mutate("Y(0)" = y,
         "Y(1)" = y) %>%
  rename(Pair = pair, "Unit Index" = unit, W = w, "Y$^{obs}$" = y) %>%
  kable(align = c(rep("c", 6))) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
````

### Computional Shortcut

To create the the distribution of the test statistic under this sharp null hypothesis, we could permute the treatment vector, express for each unit the outcome observed according to the permuted value of the treatment and then compute the average of pair differences. This is a bit cumberstone in terms of programming. In the chapter II of his textbook, Paul Rosenbaum offers a more efficient procedure:

* For each unit *i* of each pair *j*, its observed outcome is equal to $Y_{i,j} = W_{i,j}\times Y_{i,j}(1) + (1-W_{i,j})*Y_{i,j}(0)$.
* The difference in outcomes for the pair *i* (i.e., the difference in outcomes between the treated and control units) is equal to $D_{i} = (W_{i,1} - W_{i,2})(Y_{i,1} - Y_{i,2})$
* Under the sharp null hypothesis of no effect, we have $Y_{i,j}(0) = Y_{i,j}(1)$ so that $D_{i} = (W_{i,1} - W_{i,2})(Y_{i,1}(0) - Y_{i,2}(0))$.
* If the treatment allocation within a pair is $(W_{i,1},  W_{i,2})$ = (0,1), $D_{i} = - (Y_{i,1}(0) - Y_{i,2}(0))$. If the treatment allocation is $(W_{i,1},  W_{i,2})$ = (1,0), $D_{i} = Y_{i,1}(0) - Y_{i,2}(0)$.
* **Therefore, under the sharp null hypotheis of no effect, the randomization of the treatment only changes the sign of the pair differences in outcomes.**

In terms of programming, we can proceed as follows:

1. We first compute the observed average of pair differences. We are now working with a table with 10 pair differences.
2. We then compute the permutations matrix of all possible treatment assignments This is a matrix of 10 rows with 1024 columns.
3. For each vector of treatment assignment, we compute the average of pair differences.


### Computing the Null Distribution of the Test Statistic

We compute the observed average of pair differences:

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# compute average_observed_pair_differences
average_observed_pair_differences <- data %>%
  group_by(pair) %>%
  summarise(pair_difference = y[2] - y[1]) %>%
  ungroup() %>%
  summarise(average_pair_differences = mean(pair_difference)) %>%
  pull(average_pair_differences)

# display average_observed_pair_differences
average_observed_pair_differences
````

We have already computed the permutations matrix of all treatment assignments and we load this matrix:

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# open the matrix of treatment permutations
permutations_matrix <- readRDS(here::here("1.data", "permutations_matrix.rds"))
````

We store the vector of observed pair differences :

```{r, echo = TRUE, message = FALSE, warning = FALSE}
observed_pair_differences <- data %>%
  group_by(pair) %>%
  summarise(pair_difference = y[2] - y[1]) %>%
  ungroup() %>%
  pull(pair_difference)
````

We then create a function to compute the randomization distribution of the test statistic:

```{R, echo=TRUE}
# randomization distribution function
# this function takes the vector of pair differences
# and then compute the average pair difference according 
# to the permuted treatment assignment
function_randomization_distribution <- function(vector_pair_difference) {
  randomization_distribution = NULL
  n_columns = dim(permutations_matrix)[2]
  for (i in 1:n_columns) {
    randomization_distribution[i] =  sum(vector_pair_difference * permutations_matrix[, i]) / 10
  }
  return(randomization_distribution)
}
````

We run this function:

```{R, echo=TRUE}
# get the distribution of permuted test statistics
distribution_test_statistics <- function_randomization_distribution(observed_pair_differences)
````

We plot below the distribution of the test statistic under the sharp null hypothesis:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# make the graph
graph_distribution_test_statistic <- tibble(distribution_test_statistics = distribution_test_statistics) %>%
  ggplot(., aes(x = distribution_test_statistics)) +
  geom_histogram(colour = "white", fill = "deepskyblue3") +
  geom_vline(xintercept = average_observed_pair_differences, size = 1.2, colour = "coral") +
  xlab("Permuted Test Statistics") + ylab("Counts") +
  custom_theme +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)))
  
# display the graph
graph_distribution_test_statistic

# save the graph
ggsave(graph_distribution_test_statistic, filename = here::here("3.outputs", "distribution_test_statistic_sharp_null.pdf"), 
       width = 40, height = 20, units = "cm", device = cairo_pdf)
```

### Computing the Two-Sided P-Value

To compute a two-sided *p*-value, we again follow the explanations provided by Paul Rosenbaum in the chapter II of his textbook:

1. We first compute both the proportions of permuted test statistics that are lower or higher than the observed test statistic.
2. We then double the smallest proportion.
3. We take the minimum of its value and one.

We implement this procedure as follows:

```{R, echo=TRUE}
# compute upper proportion
upper_p_value <- sum(distribution_test_statistics >= average_observed_pair_differences)/1024

# compute lower proportion
lower_p_value <- sum(distribution_test_statistics <= average_observed_pair_differences)/1024

# double the smallest proportion
double_smallest_proprotion <- min(c(upper_p_value, lower_p_value))*2

# take the minimum of this proprotion and one
min(double_smallest_proprotion, 1)
````

The two-sided *p*-value for the sharp null hypothesis of no effect is equal to 0.5527344.

# Computing a 95% Fisherian Intervals

We follow here the explanations provided by Tirthankar Dasguspta and Donald B. Rubin in their forthcoming textbook on experimental design: *Experimental Design: A Randomization-Based Perspective*.

### Steps of the Procedure

Instead of gauging a null effect for all units, we test a set of \textit{K} sharp null hypotheses $H_{0}^{k}$: Y$_{i,j}$(1) =  Y$_{i,j}$(0) + $\tau_{k}$ for *k* =1,$\ldots$, \textit{K} and where $\tau_{k}$ represents a constant unit-level treatment effect size. 

We must therefore choose of set of constant treatment effects that we would like to test. Here, we test a set of 81 sharp null hypotheses of constant treatment effects ranging from -20 \si{\ugpcm} to +20 \si{\ugpcm} with increments of 0.5\si{\ugpcm}. 

For each constant treatment effect \textit{k}, we compute the upper \textit{p}-value associated with the hypothesis $H_{0}^{k}$: Y$_{i,j}$(1) - Y$_{i,j}$(0) $>$ $\tau_{k}$ and the lower \textit{p}-value $H_{0}^{k}$: Y$_{i,j}$(1) - Y$_{i,j}$(0) $<$ $\tau_{k}$. 

To test each hypothesis, we compute the distribution of the test statistic. The sequence of \textit{K} hypotheses $H_{0}^{k}$: Y$_{i,j}$(1) - Y$_{i,j}$(0) $>$ $\tau_{k}$ forms an upper \textit{p}-value function of $\tau$, $p^{+}(\tau)$, while the sequence of alternative hypotheses $H_{0}^{k}$: Y$_{i,j}$(1) - Y$_{i,j}$(0) $<$ $\tau_{k}$ makes a lower \textit{p}-value function,  $\tau$, $p^{-}(\tau)$. To compute the bounds of the 100(1-$\alpha$)\% Fisherian interval, we solve $p^{+}(\tau) = \frac{\alpha}{2}$ for $\tau$ to get the lower limit and $p^{-}(\tau) = \frac{\alpha}{2}$ for the upper limit. We set our $\alpha$ significance level to 0.05 and thus compute 95\% Fisherian intervals. This procedure allows us to get the range of \textit{constant} treatment effects consistent with our data. 

As a point estimate of a Fisherian interval, we take the observed value of our test statistic which is the average of pair differences in a pollutant concentration. **For avoiding confusion, it is very important to note that our test statistic is an estimate for the individual-level treatment effect of an hypothetical experiment and not for the average treatment effect.**

### Computational Shortcut

For each hypothesis, we could impute the missing potential outcomes. Then, we would randomly allocate the treatment, express the observed outcome and finally compute the average of pair differences. Again, this is a cumbersome way to proceed. Instead, we use again a computional shortcut provided by Paul Rosenbaum in his textbook.

* We start by making a sharp hypothesis of a constant treatment effect $\tau$ such that $Y_{i,j}(1) =  Y_{i,j}(0) + \tau$.
* For a pair *i*, recall that the observed pair difference in outcomes is $D_{i} = (W_{i,1} - W_{i,2})(Y_{i,1} - Y_{i,2})$.
* Under the sharp hypothesis, we have $D_{i} = (W_{i,1} - W_{i,2})((Y_{i,1} + \tau W_{i,1}) - (Y_{i,2} + \tau W_{i,2}))$.
* We rearrange the right-hand side expression and find that  $D_{i} = \tau + (W_{i,1} - W_{i,2})(Y_{i,1}(0) - Y_{i,2}(0))$
* We have $D_{i} - \tau = (W_{i,1} - W_{i,2})(Y_{i,1}(0) - Y_{i,2}(0))$. This equation means that the observed pair difference in outcomes minus the hypothesized treatment effect is equal to  $\pm(Y_{i,1}(0) - Y_{i,2}(0))$. We can therefore carry out the randomization inference procedure seen in the previous section from the vector of observed pair differences adjusted for the hypothesized treatment effect.

### Implementation in R

We start by creating a nested tibble of our vector of observed pair differences with the set of constant treatment effect sizes we want to test:

```{R, echo=TRUE}
# create a nested dataframe with 
# the set of constant treatment effect sizes
# and the vector of observed pair differences
ri_data_fi <- tibble(observed_pair_differences = observed_pair_differences) %>%
  summarise(data_observed_pair_differences = list(observed_pair_differences)) %>%
  group_by(data_observed_pair_differences) %>%
  expand(effect = seq(from = -20, to = 20, by = 0.5)) %>%
  ungroup()

# display the nested table
ri_data_fi
````
 
We then substract for each pair difference the hypothetical constant effect:

```{R, echo=TRUE}
# function to get the observed statistic
adjusted_pair_difference_function <- function(data_observed_pair_differences, effect){
  adjusted_pair_difference <- data_observed_pair_differences-effect
  return(adjusted_pair_difference)
} 

# compute the adjusted pair differences
ri_data_fi <- ri_data_fi %>%
  mutate(data_adjusted_pair_difference = map2(data_observed_pair_differences, effect, ~ adjusted_pair_difference_function(.x, .y)))

# display the table
ri_data_fi
````

We compute the observed mean of adjusted pair differences:

```{R, echo=TRUE}
# compute the observed mean of adjusted pair differences
ri_data_fi <- ri_data_fi %>%
  mutate(observed_mean_difference = map(data_adjusted_pair_difference, ~ mean(.))) %>%
  unnest(cols = c(observed_mean_difference)) %>%
  select(-data_observed_pair_differences) %>%
  ungroup()

# display the table
ri_data_fi
````  

We use the same `function_randomization_distribution` to compute the randomization distribution of the test statistic for each hypothesized constant effect:

```{R, echo=TRUE}
# randomization distribution function
# this function takes the vector of pair differences
# and then compute the average pair difference according 
# to the permuted treatment assignment
function_randomization_distribution <- function(data_adjusted_pair_difference) {
  randomization_distribution = NULL
  n_columns = dim(permutations_matrix)[2]
  for (i in 1:n_columns) {
    randomization_distribution[i] =  sum(data_adjusted_pair_difference * permutations_matrix[, i]) / 10
  }
  return(randomization_distribution)
}
````  

We run the function:

```{R, echo=TRUE}
# compute the test statistic distribution
ri_data_fi <- ri_data_fi %>%
  mutate(randomization_distribution = map(data_adjusted_pair_difference, ~ function_randomization_distribution(.)))

# display the table
ri_data_fi
````  

We compute the lower and upper *p*-values functions. From these functions, we retrieve the lower and upper bound of the 95% Fisherian intervals:

```{R, echo=TRUE}
# define the p-values functions
function_fisher_upper_p_value <- function(observed_mean_difference, randomization_distribution){
  sum(randomization_distribution >= observed_mean_difference)/1024
}

function_fisher_lower_p_value <- function(observed_mean_difference, randomization_distribution){
  sum(randomization_distribution <= observed_mean_difference)/1024
}

# compute the lower and upper one-sided p-values
ri_data_fi <- ri_data_fi %>%
  mutate(p_value_upper = map2_dbl(observed_mean_difference, randomization_distribution, ~ function_fisher_upper_p_value(.x, .y)),
         p_value_lower = map2_dbl(observed_mean_difference, randomization_distribution, ~ function_fisher_lower_p_value(.x, .y)))
````  

We plot below the lower and upper *p*-values functions:

```{R, echo=FALSE, message = FALSE, warning = FALSE, fig.fullwidth=TRUE, fig.width=15, fig.height=8, dev = "CairoPNG"}
# make the graph
graph_p_value_functions <- ri_data_fi %>%
  select(effect, p_value_upper, p_value_lower) %>%
  rename("Upper p-value Function" = p_value_upper, "Lower p-value Function" = p_value_lower) %>%
  pivot_longer(cols = -c(effect), names_to = "lower_upper", values_to = "p_value") %>%
  ggplot(., aes(x = effect, y = p_value)) +
  geom_hline(yintercept = 0.025, colour = "coral", size = 1.05) +
  geom_line(colour = "deepskyblue3", size = 2) +
  facet_wrap(~ fct_rev(lower_upper)) +
  xlab("τ") + ylab("p-value") +
  custom_theme

# display the graph
graph_p_value_functions

# save the graph
ggsave(graph_p_value_functions, filename = here::here("3.outputs", "graph_p_value_functions.pdf"), 
       width = 40, height = 20, units = "cm", device = cairo_pdf)
````

The orange line represents the alpha signifance level, set at 5%, divided by two. We then retrieve the lower and upper bound of the 95% Fisherian interval:

```{R, echo=TRUE}
# retrieve the constant effects with the p-values equal or the closest to 0.025
ri_data_fi <- ri_data_fi %>%
  mutate(p_value_upper = abs(p_value_upper - 0.025),
         p_value_lower = abs(p_value_lower - 0.025)) %>%
  filter(p_value_upper == min(p_value_upper) | p_value_lower == min(p_value_lower)) %>%
# in case two effect sizes have a p-value equal to 0.025, we take the effect size
# that make the Fisherian interval wider to be conservative
  summarise(lower_fi = min(effect),
            upper_fi = max(effect))

# display the lower and upper bounds
ri_data_fi
````  

As a point estimate, we take the value of the observed average of pair differences, that is to say `r average_observed_pair_differences`. For this imaginary experiment, our point estimate is close to the true constant effect but the 95% Fisherian interval is wide: the data are consistent with both large negative and positive constant treatment effects.




