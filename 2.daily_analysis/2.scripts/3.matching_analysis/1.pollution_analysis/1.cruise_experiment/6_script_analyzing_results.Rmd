---
title: "Analyzing Results"
description: |
  Comparing days with one cruise vessels entering the port to days without. Adjusting for calendar and weather indicators.
authors:
  - name: Léo Zabrocki 
    url: https://www.parisschoolofeconomics.eu/en/
    affiliation: Paris School of Economics
    affiliation_url: https://www.parisschoolofeconomics.eu/en/
  - name: Marion Leroutier 
    url: https://marionleroutier.weebly.com/
    affiliation: Mistra Center for Sustainable Markets, Stockholm School of Economics
    affiliation_url: https://www.hhs.se/en/persons/l/leroutier-marion/
  - name: Marie-Abèle Bind 
    url: https://biostatistics.massgeneral.org/faculty/marie-abele-bind-phd/
    affiliation: Biostatistics Center, Massachusetts General Hospital
    affiliation_url: https://biostatistics.massgeneral.org/faculty/marie-abele-bind-phd/
date: "`r Sys.Date()`"
output: 
    distill::distill_article:
      toc: true
      toc_depth: 3
---

<style>
body {
text-align: justify}
</style>

In this document, we take great care providing all steps and R codes required to analyze the effects of cruise traffic on air pollutants at the daily level.  We compare days where:

* treated units are days with one cruise vessel entering the port in *t*.
* control units are day with zero cruise vessel entering the port in *t*.

We adjust for calendar indicator and weather confouding factors.

**Should you have any questions, need help to reproduce the analysis or find coding errors, please do not hesitate to contact us at leo.zabrocki@psemail.eu and marion.leroutier@hhs.se.**

# Required Packages

To reproduce exactly the `6_script_analyzing_results.html` document, we first need to have installed:

* the [R](https://www.r-project.org/) programming language 
* [RStudio](https://rstudio.com/), an integrated development environment for R, which will allow you to knit the `5_script_checking_balance_figures.Rmd` file and interact with the R code chunks
* the [R Markdown](https://rmarkdown.rstudio.com/) package
* and the [Distill](https://rstudio.github.io/distill/) package which provides the template for this document. 

Once everything is set up, we have to load the following packages:

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# load required packages
library(knitr) # for creating the R Markdown document
library(here) # for files paths organization
library(tidyverse) # for data manipulation and visualization
library(retrodesign) # for assessing type m and s errors
library(Cairo) # for printing customed police of graphs
library(patchwork) # combining plots
```

We finally load our customed `ggplot2` theme for graphs:

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# load ggplot customed theme
source(here::here("2.scripts", "5.custom_ggplot2_theme", "script_custom_ggplot_theme.R"))
````

The theme is based on the fantastic [hrbrthemes](https://hrbrmstr.github.io/hrbrthemes/index.html) package. If you do not want to use this theme or are unable to install it because of fonts issues, you can use the `theme_bw()` already included in the `ggplot2` package.

# Preparing the Data

We load the matched data:

```{R, echo = TRUE}
# load matched data
data_matched <- readRDS(here::here("1.data", "2.data_for_analysis", "1.cruise_experiment", "matched_data.rds")) 
```

# Distribution of the Pair Differences in Concentration between Treated and Control units for each Pollutant

### Computing Pairs Differences in Pollutant Concentrations

We first compute the differences in a pollutant's concentration for each pair over time:

```{R, echo=TRUE}
data_matched_wide <- data_matched %>%
    mutate(is_treated = ifelse(is_treated == TRUE, "treated", "control")) %>%
  select(is_treated, pair_number, contains("mean_no2_l"), contains("mean_no2_sl"), contains("mean_o3"), contains("mean_pm10_l"), contains("mean_pm10_sl"), contains("mean_pm25"), contains("mean_so2")) %>%
  pivot_longer(cols = -c(pair_number, is_treated), names_to = "variable", values_to = "concentration") %>%
  mutate(pollutant = NA %>%
           ifelse(str_detect(variable, "no2_l"), "NO2 Longchamp",.) %>%
           ifelse(str_detect(variable, "no2_sl"), "NO2 Saint-Louis",.) %>%
           ifelse(str_detect(variable, "o3"), "O3 Longchamp",.) %>%
           ifelse(str_detect(variable, "pm10_l"), "PM10 Longchamp",.) %>%
           ifelse(str_detect(variable, "pm10_sl"), "PM10 Saint-Louis",.) %>%
           ifelse(str_detect(variable, "pm25"), "PM2.5 Longchamp",.) %>%
           ifelse(str_detect(variable, "so2"), "SO2 Lonchamp",.)) %>%
  mutate(time = 0 %>%
           ifelse(str_detect(variable, "lag_1"), -1, .) %>%
           ifelse(str_detect(variable, "lead_1"), 1, .)) %>%
  select(-variable) %>%
  select(pair_number, is_treated, pollutant, time, concentration) %>% 
  pivot_wider(names_from = is_treated, values_from = concentration)

data_pair_difference_pollutant <- data_matched_wide %>%
  mutate(difference = treated-control) %>%
  select(-c(treated, control)) 
````

### Pairs Differences in NO2 Concentrations

Boxplots for NO2:

```{R, echo=TRUE, layout="l-body-outset", fig.width=20, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# create the graph for no2
graph_boxplot_difference_pollutant_no2 <- data_pair_difference_pollutant %>%
  filter(str_detect(pollutant, "NO2")) %>%
  ggplot(., aes(x = as.factor(time), y = difference)) +
  geom_boxplot(colour = "deepskyblue3") +
  facet_wrap(~ pollutant) +
  ylab("Pair Difference in \nConcentration (µg/m3)") + xlab("Day") +
  custom_theme

# display the graph
graph_boxplot_difference_pollutant_no2

# save the graph
ggsave(graph_boxplot_difference_pollutant_no2, filename = here::here("3.outputs", "1.figures", "2.analysis_pollution", "1.cruise_experiment", "2.matching_results", "graph_boxplot_difference_pollutant_no2.pdf"), 
       width = 30, height = 15, units = "cm", device = cairo_pdf)
````

### Pairs Differences in O3 Concentrations

Boxplots for O3:

```{R, echo=TRUE, layout="l-body-outset", fig.width=20, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# create the graph for o3
graph_boxplot_difference_pollutant_o3 <- data_pair_difference_pollutant %>%
  filter(str_detect(pollutant, "O3")) %>%
  ggplot(., aes(x = as.factor(time), y = difference)) +
  geom_boxplot(colour = "deepskyblue3") +
  ylab("Pair Difference in \nConcentration (µg/m3)") + xlab("Day") +
  custom_theme

# display the graph
graph_boxplot_difference_pollutant_o3

# save the graph
ggsave(graph_boxplot_difference_pollutant_o3, filename = here::here("3.outputs", "1.figures", "2.analysis_pollution", "1.cruise_experiment", "2.matching_results", "graph_boxplot_difference_pollutant_o3.pdf"), 
       width = 30, height = 15, units = "cm", device = cairo_pdf)
````

### Pairs Differences in PM10 Concentrations

Boxplots for PM10:

```{R, echo=TRUE, layout="l-body-outset", fig.width=20, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# create the graph for pm10
graph_boxplot_difference_pollutant_pm10 <- data_pair_difference_pollutant %>%
  filter(str_detect(pollutant, "PM10")) %>%
  ggplot(., aes(x = as.factor(time), y = difference)) +
  geom_boxplot(colour = "deepskyblue3") +
  facet_wrap(~ pollutant) +
  ylab("Pair Difference in \nConcentration (µg/m3)") + xlab("Day") +
  custom_theme

# display the graph
graph_boxplot_difference_pollutant_pm10

# save the graph
ggsave(graph_boxplot_difference_pollutant_pm10, filename = here::here("3.outputs", "1.figures", "2.analysis_pollution", "1.cruise_experiment", "2.matching_results", "graph_boxplot_difference_pollutant_pm10.pdf"), 
       width = 30, height = 15, units = "cm", device = cairo_pdf)
````

### Pairs Differences in PM2.5 Concentrations

Boxplots for PM2.5:

```{R, echo=TRUE, layout="l-body-outset", fig.width=20, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# create the graph for pm2.5
graph_boxplot_difference_pollutant_pm25 <- data_pair_difference_pollutant %>%
  filter(str_detect(pollutant, "PM2.5")) %>%
  ggplot(., aes(x = as.factor(time), y = difference)) +
  geom_boxplot(colour = "deepskyblue3") +
  ylab("Pair Difference in \nConcentration (µg/m3)") + xlab("Day") +
  custom_theme

# display the graph
graph_boxplot_difference_pollutant_pm25

# save the graph
ggsave(graph_boxplot_difference_pollutant_pm25, filename = here::here("3.outputs", "1.figures", "2.analysis_pollution", "1.cruise_experiment", "2.matching_results", "graph_boxplot_difference_pollutant_pm25.pdf"), 
       width = 30, height = 15, units = "cm", device = cairo_pdf)
````

### Pairs Differences in SO2 Concentrations

Boxplots for SO2:

```{R, echo=TRUE, layout="l-body-outset", fig.width=20, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# create the graph for so2
graph_boxplot_difference_pollutant_so2 <- data_pair_difference_pollutant %>%
  filter(str_detect(pollutant, "SO2")) %>%
  ggplot(., aes(x = as.factor(time), y = difference)) +
  geom_boxplot(colour = "deepskyblue3") +
  ylab("Pair Difference in \nConcentration (µg/m3)") + xlab("Day") +
  custom_theme

# display the graph
graph_boxplot_difference_pollutant_so2

# save the graph
ggsave(graph_boxplot_difference_pollutant_so2, filename = here::here("3.outputs", "1.figures", "2.analysis_pollution", "1.cruise_experiment", "2.matching_results", "graph_boxplot_difference_pollutant_so2.pdf"), 
       width = 30, height = 15, units = "cm", device = cairo_pdf)
````

# Testing the Sharp Null Hypothesis

We test the sharp null hypothesis of no effect for any units. We first create a dataset where we nest the pair differences by pollutant and time. We also compute the observed test statistic which is the observed average of pair differences:

```{R, echo=TRUE}
# nest the data by pollutant and time
ri_data_sharp_null <- data_pair_difference_pollutant   %>%
  select(pollutant, time, difference) %>%
  group_by(pollutant, time) %>%
  mutate(observed_mean_difference = mean(difference)) %>%
  group_by(pollutant, time, observed_mean_difference) %>%
  summarise(data_difference = list(difference))
````

We then create a function to compute the randomization distribution of the test statistic:

```{R, echo=TRUE}
# randomization distribution function
# this function takes the vector of pair differences
# and then compute the average pair difference according 
# to the permuted treatment assignment
function_randomization_distribution <- function(data_difference) {
  randomization_distribution = NULL
  n_columns = dim(permutations_matrix)[2]
  for (i in 1:n_columns) {
    randomization_distribution[i] =  sum(data_difference * permutations_matrix[, i]) / number_pairs
  }
  return(randomization_distribution)
}
````

We store the number of pairs and the number of simulations we want to run:

```{R, echo=TRUE}
# define number of pairs in the experiment
number_pairs <- nrow(data_matched)/2

# define number of simulations
number_simulations <- 100000
````

We compute the permutations matrix:

```{R, echo=TRUE}
# set seed
set.seed(42)

# compute the permutations matrix
permutations_matrix <- matrix(rbinom(number_pairs*number_simulations, 1,.5)*2-1, nrow = number_pairs, ncol = number_simulations)
````

For each pollutant and time, we compute the randomization distribution of the test statistic using 100,000 iterations. It took us 46 seconds to run this code chunck on our basic local computer:

```{R, echo=TRUE}
# set seed
set.seed(42)

# compute the test statistic distribution
ri_data_sharp_null <- ri_data_sharp_null %>%
  mutate(randomization_distribution = map(data_difference, ~ function_randomization_distribution(.)))
````

Using the observed value of the test statistic and its randomization distribution, we compute the two-sided *p*-values:

```{R, echo=TRUE}
# function to compute the upper one-sided p-value
function_fisher_upper_p_value <- function(observed_mean_difference, randomization_distribution){
  sum(randomization_distribution >= observed_mean_difference)/number_simulations
}

# function compute the lower one-sided p-value
function_fisher_lower_p_value <- function(observed_mean_difference, randomization_distribution){
  sum(randomization_distribution <= observed_mean_difference)/number_simulations
}

# compute the lower and upper one-sided p-values
ri_data_sharp_null <- ri_data_sharp_null %>%
  mutate(p_value_upper = map2_dbl(observed_mean_difference, randomization_distribution, ~ function_fisher_upper_p_value(.x, .y)),
         p_value_lower = map2_dbl(observed_mean_difference, randomization_distribution, ~ function_fisher_lower_p_value(.x, .y)))

# compute the two-sided p-value using rosenbaum (2010) procedure
ri_data_sharp_null <- ri_data_sharp_null %>%
  rowwise() %>%
  mutate(two_sided_p_value = min(c(p_value_upper, p_value_lower))*2) %>%
  mutate(two_sided_p_value = min(two_sided_p_value, 1)) %>%
  select(pollutant, time, observed_mean_difference, two_sided_p_value) %>%
  ungroup()
````


We plot below the two-sided p-values for the sharp null hypothesis for each pollutant:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# make the graph
graph_p_values <- ri_data_sharp_null %>%
  ggplot(., aes(x = as.factor(time), y = two_sided_p_value)) +
  geom_segment(aes(x = as.factor(time), xend = as.factor(time), y = 0, yend = two_sided_p_value)) +
  geom_point(shape = 21, size = 8, colour = "black", fill = "deepskyblue3") +
  facet_wrap(~ pollutant, ncol = 4) +
  xlab("Day") + ylab("Two-Sided P-Value") +
  custom_theme +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # axis texts
    axis.text.x = element_text(size=20),
    axis.text.y = element_text(size=20),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"))
  
# display the graph
graph_p_values

# save the graph
ggsave(graph_p_values, filename = here::here("3.outputs", "1.figures", "2.analysis_pollution", "1.cruise_experiment", "2.matching_results", "graph_p_values.pdf"), 
       width = 60, height = 25, units = "cm", device = cairo_pdf)
```

We display below the table of Fisher p-values:

```{r, echo = FALSE, layout="l-body-outset"}
ri_data_sharp_null %>%
  select(pollutant, time, observed_mean_difference, two_sided_p_value) %>%
  rename("Pollutant" = pollutant, "Time" = time, "Observed Value of the Test Statistic" = observed_mean_difference, "Two-Sided P-Values"= two_sided_p_value) %>%
  rmarkdown::paged_table(.)
````

# Computing Fisherian intervals

To compute Fisherian intervals, we first create a nested dataset with the pair differences for each pollutant and day. We also add the set of hypothetical constant effects.

```{R, echo=TRUE}
# create a nested dataframe with 
# the set of constant treatment effect sizes
# and the vector of observed pair differences
ri_data_fi <- data_pair_difference_pollutant %>%
  select(pollutant, time, difference) %>%
  group_by(pollutant, time) %>%
  summarise(data_difference = list(difference)) %>%
  group_by(pollutant, time, data_difference) %>%
  expand(effect = seq(from = -10, to = 10, by = 0.1)) %>%
  ungroup()
````
 
We then subtract for each pair difference the hypothetical constant effect:

```{R, echo=TRUE}
# function to get the observed statistic
adjusted_pair_difference_function <- function(pair_differences, effect){
  adjusted_pair_difference <- pair_differences-effect
  return(adjusted_pair_difference)
} 

# compute the adjusted pair differences
ri_data_fi <- ri_data_fi %>%
  mutate(data_adjusted_pair_difference = map2(data_difference, effect, ~ adjusted_pair_difference_function(.x, .y)))
````

We compute the observed mean of adjusted pair differences:

```{R, echo=TRUE}
# compute the observed mean of adjusted pair differences
ri_data_fi <- ri_data_fi %>%
  mutate(observed_mean_difference = map(data_adjusted_pair_difference, ~ mean(.))) %>%
  unnest(cols = c(observed_mean_difference)) %>%
  select(-data_difference) %>%
  ungroup()
````  

We use the same `function_randomization_distribution` to compute the randomization distribution of the test statistic but only run 100,000 iterations for each pollutant-day observation:

```{R, echo=TRUE}
# define number of pairs in the experiment
number_pairs <- nrow(data_matched)/2

# define number of simulations
number_simulations <- 100000

# set seed
set.seed(42)

# compute the permutations matrix
permutations_matrix <- matrix(rbinom(number_pairs*number_simulations, 1,.5)*2-1, nrow = number_pairs, ncol = number_simulations)

# randomization distribution function
# this function takes the vector of pair differences
# and then compute the average pair difference according 
# to the permuted treatment assignment
function_randomization_distribution <- function(data_difference) {
  randomization_distribution = NULL
  n_columns = dim(permutations_matrix)[2]
  for (i in 1:n_columns) {
    randomization_distribution[i] =  sum(data_difference * permutations_matrix[, i]) / number_pairs
  }
  return(randomization_distribution)
}
````  

We ran the function It took about 25 minutes to run on our laptop. To quickly compile the .Rmd document, we therefore store the results of the simulations. The code we used is displayed below:

```{R, echo=TRUE}
# set seed
set.seed(42)

# compute the test statistic distribution
ri_data_fi <- ri_data_fi %>%
  mutate(randomization_distribution = map(data_adjusted_pair_difference, ~ function_randomization_distribution(.)))

#----------------------------------------------------

# Computing the lower and upper *p*-values functions

#----------------------------------------------------

# define the p-values functions
function_fisher_upper_p_value <- function(observed_mean_difference, randomization_distribution){
  sum(randomization_distribution >= observed_mean_difference)/number_simulations
}

function_fisher_lower_p_value <- function(observed_mean_difference, randomization_distribution){
  sum(randomization_distribution <= observed_mean_difference)/number_simulations
}

# compute the lower and upper one-sided p-values
ri_data_fi <- ri_data_fi %>%
  mutate(p_value_upper = map2_dbl(observed_mean_difference, randomization_distribution, ~ function_fisher_upper_p_value(.x, .y)),
         p_value_lower = map2_dbl(observed_mean_difference, randomization_distribution, ~ function_fisher_lower_p_value(.x, .y)))

#----------------------------------------------------------

# RETRIEVING LOWER AND UPPER BOUNDS OF FISHERIAN INTERVALS

#----------------------------------------------------------

# retrieve the constant effects with the p-values equal or the closest to 0.025
ri_data_fi <- ri_data_fi %>%
  mutate(p_value_upper = abs(p_value_upper - 0.025),
         p_value_lower = abs(p_value_lower - 0.025)) %>%
  group_by(pollutant, time) %>%
  filter(p_value_upper == min(p_value_upper) | p_value_lower == min(p_value_lower)) %>%
# in case two effect sizes have a p-value equal to 0.025, we take the effect size
# that make the Fisherian interval wider to be conservative
  summarise(lower_fi = min(effect),
            upper_fi = max(effect))

#----------------------------------------------------------

# COMPUTING POINT ESTIMATES

#----------------------------------------------------------

# compute observed average of pair differences
ri_data_fi_point_estimate <- data_pair_difference_pollutant   %>%
  select(pollutant, time, difference) %>%
  group_by(pollutant, time) %>%
  summarise(observed_mean_difference = mean(difference)) %>%
  ungroup()

#----------------------------------------------------------

# MERGING POINT ESTIMATES WITH INTERVALS

#----------------------------------------------------------

# merge ri_data_fi_point_estimate with ri_data_fi
ri_data_fi_final <- left_join(ri_data_fi, ri_data_fi_point_estimate, by = c("pollutant", "time"))

# create an indicator to alternate shading of confidence intervals
ri_data_fi_final <- ri_data_fi_final %>%
  arrange(pollutant, time) %>%
  mutate(stripe = ifelse((time %% 2) == 0, "Grey", "White")) %>%
  ungroup()

# save the data
saveRDS(ri_data_fi_final, here::here("1.data", "2.data_for_analysis", "1.cruise_experiment", "ri_data_fisherian_intervals.rds"))
````  

We plot below the 95% Fisherian intervals:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# read the data on 95% fisherian intervals
ri_data_fi_final <- readRDS(here::here("1.data", "2.data_for_analysis", "1.cruise_experiment", "ri_data_fisherian_intervals.rds"))

# make the graph
graph_fisherian_intervals <- ggplot(ri_data_fi_final, aes(x = as.factor(time), y = observed_mean_difference)) +
      geom_rect(aes(fill = stripe), xmin = as.numeric(as.factor(ri_data_fi_final$time))-0.42,
            xmax = as.numeric(as.factor(ri_data_fi_final$time))+0.42, ymin = -Inf, ymax=Inf, color = NA, alpha = 0.4) +
  geom_hline(yintercept = 0, color="black") +
  geom_vline(xintercept = "0", color = "black") +
  geom_pointrange(aes(x = as.factor(time), y = observed_mean_difference, ymin = lower_fi ,
                      ymax = upper_fi), colour="deepskyblue3", lwd = 1.2) +
  facet_wrap(~ pollutant, scales = "free_y", ncol = 4) +
  scale_fill_manual(values = c('gray96', NA)) +
  guides(fill = FALSE) +
  ylab("Constant-Additive Increase \nin Concentrations (µg/m³)") + xlab("Day") +
  custom_theme +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"))

# print the graph
graph_fisherian_intervals

# save the graph
ggsave(graph_fisherian_intervals, filename = here::here("3.outputs", "1.figures", "2.analysis_pollution", "1.cruise_experiment", "2.matching_results", "graph_fisherian_intervals.pdf"), width = 70, height = 30, units = "cm", device = cairo_pdf)
```

We display below the table with the 95% fiducial intervals and the Hodges-Lehmann point estimates:

```{r, echo = FALSE, layout="l-body-outset"}
ri_data_fi_final %>%
  select(pollutant, time, observed_mean_difference, lower_fi, upper_fi) %>%
  mutate(observed_mean_difference = round(observed_mean_difference, 1)) %>%
  rename("Pollutant" = pollutant, "Time" = time, "Point Estimate" = observed_mean_difference, "Lower Bound of the 95% Fisherian Interval" = lower_fi, "Upper Bound of the 95% Fisherian Interval" = upper_fi) %>%
  rmarkdown::paged_table(.)
````

# Checking the Sensivity of Results

In this section, we carry out four investigations:

* We check how our results are sensitive to outliers by computing 95% fiducial intervals based on the Wilcoxon's signed rank test statistic.
* As we imputed the missing pollutant concentrations, we also want to see how our results might for the non-missing outcomes. We compute 95% fiducial intervals based on the Wilcoxon's signed rank test statistic.
* We compute confidence intervals for the average treatment effect using Neyman's approach.
* We explore how our study could suffer from type S and M errors.

### Outliers

To gauge how sensitive our results are to outliers, we use a Wilcoxon signed rank test statistic and compute 95% fiducial intervals using the `wilcox.test()` function.

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# carry out the wilcox.test 
data_rank_ci <- data_pair_difference_pollutant %>%
  select(- pair_number) %>%
  group_by(pollutant, time) %>%
  nest() %>%
  mutate(effect = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$estimate),
         lower_ci = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$conf.int[1]),
         upper_ci = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$conf.int[2])) %>%
  unnest(cols = c(effect, lower_ci, upper_ci)) %>%
  mutate(data = "Wilcoxon Rank Test Statistic")

# bind ri_data_fi_final with data_rank_ci
data_ci <- ri_data_fi_final %>%
  rename(effect = observed_mean_difference, lower_ci = lower_fi, upper_ci = upper_fi) %>%
  mutate(data = "Average Pair Difference Test Statistic") %>%
  bind_rows(., data_rank_ci)

# create an indicator to alternate shading of confidence intervals
data_ci <- data_ci %>%
  arrange(pollutant, time) %>%
  mutate(stripe = ifelse((time %% 2) == 0, "Grey", "White")) %>%
  ungroup()

# make the graph
graph_ri_ci_wilcoxon <- ggplot(data_ci, aes(x = as.factor(time), y = effect, ymin = lower_ci,
                        ymax = upper_ci, colour = data, shape = data)) +
  geom_rect(aes(fill = stripe), xmin = as.numeric(as.factor(data_ci$time))-0.42,
            xmax = as.numeric(as.factor(data_ci$time))+0.42, ymin = -Inf, ymax=Inf, color = NA, alpha = 0.4) +
  geom_hline(yintercept = 0, color="black") +
  geom_pointrange(position = position_dodge(width = 1), size = 1.2) +
  scale_shape_manual(name = "Test Statistic:", values = c(16, 17)) +
  scale_color_manual(name = "Test Statistic:", values = c("coral", "deepskyblue3")) +
  facet_wrap(~ pollutant, scales = "free_y", ncol = 4) +
  scale_fill_manual(values = c('gray92', NA)) +
  guides(fill = FALSE) +
  ylab("Constant-Additive Increase \nin Concentrations (µg/m³)") + xlab("Day") +
  custom_theme +
  theme(legend.position = "top", legend.justification = "left", legend.direction = "horizontal") +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # axis texts
    axis.text.x = element_text(size=20),
    axis.text.y = element_text(size=20),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"),
    # legend parameters
    legend.position = "top", legend.justification = "left", legend.direction = "horizontal",
    legend.title = element_text(size=36, face = "bold"),
    legend.text = element_text(size=28))

# print the graph
graph_ri_ci_wilcoxon

# save the graph
ggsave(graph_ri_ci_wilcoxon, filename = here::here("3.outputs", "1.figures", "2.analysis_pollution", "1.cruise_experiment", "2.matching_results", "graph_ri_ci_wilcoxon.pdf"), width = 70, height = 30, units = "cm", device = cairo_pdf)
```

### Missing Outcomes

We load non-imputed air pollution data and compute for each pollutant the 0-1 daily lags and leads:

```{R, echo = TRUE}
# load marseille raw air pollution data
data_marseille_raw_pollutants <- readRDS(here::here("1.data", "1.raw_data" , "3.pollution_data", "raw_marseille_pollutants_2008_2018_data.rds")) %>%
  rename_at(vars(-date), function(x) paste0("raw_", x))

# we first define data_marseille_raw_pollutants_leads and data_marseille_raw_pollutants_lags
# to store leads and lags

data_marseille_raw_pollutants_leads <- data_marseille_raw_pollutants
data_marseille_raw_pollutants_lags <- data_marseille_raw_pollutants

#
# create leads
# 

# create a list to store dataframe of leads
leads_list <- vector(mode = "list", length = 1)
names(leads_list) <- c(1) 

# create the leads
for(i in 1){
  leads_list[[i]] <- data_marseille_raw_pollutants_leads %>%
    mutate_at(vars(-date), ~  lead(., n = i, order_by = date)) %>%
    rename_at(vars(-date),function(x) paste0(x,"_lead_", i))
}

# merge the dataframes of leads
data_leads <- leads_list %>%
  reduce(left_join, by = "date")

# merge the leads with the data_marseille_raw_pollutants_leads
data_marseille_raw_pollutants_leads <- left_join(data_marseille_raw_pollutants_leads, data_leads, by = "date") %>%
  select(-c(raw_mean_no2_sl:raw_mean_o3_l))

#
# create lags
# 

# create a list to store dataframe of lags
lags_list <- vector(mode = "list", length = 1)
names(lags_list) <- c(1) 

# create the lags
for(i in 1){
  lags_list[[i]] <- data_marseille_raw_pollutants_lags %>%
    mutate_at(vars(-date), ~  lag(., n = i, order_by = date)) %>%
    rename_at(vars(-date),function(x) paste0(x,"_lag_", i))
}

# merge the dataframes of lags
data_lags <- lags_list %>%
  reduce(left_join, by = "date")

# merge the lags with the initial data_marseille_raw_pollutants_lags
data_marseille_raw_pollutants_lags <- left_join(data_marseille_raw_pollutants_lags, data_lags, by = "date")

#
# merge data_marseille_raw_pollutants_leads with data_marseille_raw_pollutants_lags
#

data_marseille_raw_pollutants <- left_join(data_marseille_raw_pollutants_lags, data_marseille_raw_pollutants_leads, by = "date")
````

We merge these data with the matched data and compute pair differences: 

```{R, echo = TRUE}
# merge with the matched_data
data_matched_with_raw_pollutants <- left_join(data_matched, data_marseille_raw_pollutants, by = "date")

# compute pair differences
data_matched_wide_raw_pollutants <- data_matched_with_raw_pollutants %>%
  mutate(is_treated = ifelse(is_treated == TRUE, "treated", "control")) %>%
  select(is_treated, pair_number, contains("raw_mean_no2_l"), contains("raw_mean_no2_sl"), contains("raw_mean_o3"), contains("raw_mean_pm10_l"), contains("raw_mean_pm10_sl"), contains("raw_mean_pm25"), contains("raw_mean_so2")) %>%
  pivot_longer(cols = -c(pair_number, is_treated), names_to = "variable", values_to = "concentration") %>%
  mutate(pollutant = NA %>%
           ifelse(str_detect(variable, "no2_l"), "NO2 Longchamp",.) %>%
           ifelse(str_detect(variable, "no2_sl"), "NO2 Saint-Louis",.) %>%
           ifelse(str_detect(variable, "o3"), "O3 Longchamp",.) %>%
           ifelse(str_detect(variable, "pm10_l"), "PM10 Longchamp",.) %>%
           ifelse(str_detect(variable, "pm10_sl"), "PM10 Saint-Louis",.) %>%
           ifelse(str_detect(variable, "pm25"), "PM2.5 Longchamp",.) %>%
           ifelse(str_detect(variable, "so2"), "SO2 Lonchamp",.)) %>%
  mutate(time = 0 %>%
           ifelse(str_detect(variable, "lag_1"), -1, .) %>%
           ifelse(str_detect(variable, "lead_1"), 1, .)) %>%
  select(-variable) %>%
  select(pair_number, is_treated, pollutant, time, concentration) %>% 
  pivot_wider(names_from = is_treated, values_from = concentration)

data_raw_pair_difference_pollutant <- data_matched_wide_raw_pollutants %>%
  mutate(difference = treated-control) %>%
  select(-c(treated, control)) 
```

We display below the number of missing differences by pollutant and day:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# make the graph
graph_missing_pollutants <- data_raw_pair_difference_pollutant %>%
  group_by(pollutant, time) %>%
  summarise(n_missing = sum(is.na(difference))) %>%
  ggplot(., aes(x = as.factor(time), y = n_missing)) +
  geom_segment(aes(x = as.factor(time), xend = as.factor(time), y = 0, yend = n_missing)) +
  geom_point(shape = 21, size = 4, colour = "black", fill = "deepskyblue3") +
  facet_wrap(~ pollutant, ncol = 4) +
  xlab("Day") + ylab("Number of Pairs with \nMissing Concentrations") +
  custom_theme
  
# display the graph
graph_missing_pollutants

# save the graph
ggsave(graph_missing_pollutants, filename = here::here("3.outputs", "1.figures", "2.analysis_pollution", "1.cruise_experiment", "2.matching_results", "graph_missing_pollutants.pdf"), 
       width = 40, height = 25, units = "cm", device = cairo_pdf)
```

As we have `r nrow(data_matched)/2` pairs, up to 21% of the pairs can have missing pollutant concentrations. We compute below the 95% fiducial intervals for pairs without missing concentrations and compare the results to those found with the imputed dataset:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# carry out the wilcox.test 
data_raw_rank_ci <- data_raw_pair_difference_pollutant %>%
  drop_na() %>%
  select(- pair_number) %>%
  group_by(pollutant, time) %>%
  nest() %>%
  mutate(effect = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$estimate),
         lower_ci = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$conf.int[1]),
         upper_ci = map(data, ~ wilcox.test(.$difference, conf.int = TRUE)$conf.int[2])) %>%
  unnest(cols = c(effect, lower_ci, upper_ci)) %>%
  mutate(data = "Pairs without Missing Concentrations")

# bind data_rank_ci with data_raw_rank_ci
data_ci <- data_rank_ci %>%
  mutate(data = "Pairs with Imputed Pollutant Concentrations") %>%
  bind_rows(., data_raw_rank_ci)

# create an indicator to alternate shading of confidence intervals
data_ci <- data_ci %>%
  arrange(pollutant, time) %>%
  mutate(stripe = ifelse((time %% 2) == 0, "Grey", "White")) %>%
  ungroup()

# make the graph
graph_ri_ci_missing_concentration <- ggplot(data_ci, aes(x = as.factor(time), y = effect, ymin = lower_ci,
                        ymax = upper_ci, colour = data, shape = data)) +
  geom_rect(aes(fill = stripe), xmin = as.numeric(as.factor(data_ci$time))-0.42,
            xmax = as.numeric(as.factor(data_ci$time))+0.42, ymin = -Inf, ymax=Inf, color = NA, alpha = 0.4) +
  geom_hline(yintercept = 0, color="black") +
  geom_pointrange(position = position_dodge(width = 1), size = 1.2) +
  scale_shape_manual(name = "Dataset:", values = c(16, 17)) +
  scale_color_manual(name = "Dataset:", values = c("coral", "deepskyblue3")) +
  facet_wrap(~ pollutant, scales = "free_y", ncol = 4) +
  scale_fill_manual(values = c('gray92', NA)) +
  guides(fill = FALSE) +
  ylab("Constant-Additive Increase \nin Concentrations (µg/m³)") + xlab("Day") +
  custom_theme +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # axis texts
    axis.text.x = element_text(size=20),
    axis.text.y = element_text(size=20),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"),
    # legend parameters
    legend.position = "top", legend.justification = "left", legend.direction = "horizontal",
    legend.title = element_text(size=36, face = "bold"),
    legend.text = element_text(size=28))

# print the graph
graph_ri_ci_missing_concentration

# save the graph
ggsave(graph_ri_ci_missing_concentration, filename = here::here("3.outputs", "1.figures", "2.analysis_pollution", "1.cruise_experiment", "2.matching_results", "graph_ri_ci_missing_concentration.pdf"), width = 70, height = 30, units = "cm", device = cairo_pdf)
``` 


### Neyman's Approach: Computing Confidence Intervals for the Average Treatment Effects

We compute confidence intervals for the average treatement using Neyman's approach. We use the formula for the standard error of pair randomized experiment found in Imbens and Rubin (2015).

```{R, echo=TRUE}
# we first compute the average treatment effects for each pollutant and hour
data_pair_mean_difference <- data_pair_difference_pollutant %>%
  group_by(pollutant, time) %>%
  summarise(mean_difference = mean(difference)) %>%
  ungroup()

# we store the number of pairs
n_pair <- nrow(data_matched)/2

# compute the standard error
data_se_neyman_pair <- left_join(data_pair_difference_pollutant, data_pair_mean_difference, by = c("pollutant", "time")) %>%
  mutate(squared_difference = (difference-mean_difference)^2) %>%
  group_by(pollutant, time) %>%
  summarise(standard_error = sqrt(1/(n_pair*(n_pair-1))*sum(squared_difference))) %>%
  select(pollutant, time, standard_error) %>%
  ungroup()

# merge the average treatment effect data witht the standard error data
data_neyman <- left_join(data_pair_mean_difference, data_se_neyman_pair, by = c("pollutant", "time")) %>%
# compute the 95% confidence intervals
  mutate(ci_lower_95 = mean_difference - 1.96*standard_error,
         ci_upper_95 = mean_difference + 1.96*standard_error)
``` 

We plot the the point estimates for the average treatment effects and their associated 95% confidence intervals:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=10, warning = FALSE, dev = "CairoPNG"}
# create an indicator to alternate shading of confidence intervals
data_neyman <- data_neyman %>%
  arrange(pollutant, time) %>%
  mutate(stripe = ifelse((time %% 2) == 0, "Grey", "White")) %>%
  ungroup()

# make the graph
graph_neyman_ci <-
  ggplot(data_neyman, aes(x = as.factor(time), y = mean_difference)) +
  geom_rect(
    aes(fill = stripe),
    xmin = as.numeric(as.factor(data_neyman$time)) - 0.42,
    xmax = as.numeric(as.factor(data_neyman$time)) + 0.42,
    ymin = -Inf,
    ymax = Inf,
    color = NA,
    alpha = 0.4
  ) +
  geom_hline(yintercept = 0, color = "black") +
  geom_vline(xintercept = "0", color = "black") +
  geom_pointrange(
    aes(
      x = as.factor(time),
      y = mean_difference,
      ymin = ci_lower_95 ,
      ymax = ci_upper_95
    ),
    colour = "deepskyblue3",
    lwd = 1.2
  ) +
  facet_wrap( ~ pollutant, scales = "free_y", ncol = 4) +
  scale_fill_manual(values = c('gray92', NA)) +
  guides(fill = FALSE) +
  ylab("Average Pair Difference \nin Concentrations (µg/m³)") + xlab("Day") +
  custom_theme +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # axis texts
    axis.text.x = element_text(size=20),
    axis.text.y = element_text(size=20),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"),
    # legend parameters
    legend.position = "top", legend.justification = "left", legend.direction = "horizontal",
    legend.title = element_text(size=36, face = "bold"),
    legend.text = element_text(size=28))

# print the graph
graph_neyman_ci

# save the graph
ggsave(
  graph_neyman_ci,
  filename = here::here(
    "3.outputs",
    "1.figures",
    "2.analysis_pollution",
    "1.cruise_experiment",
    "2.matching_results",
    "graph_ci_neyman.pdf"
  ),
  width = 70,
  height = 30,
  units = "cm",
  device = cairo_pdf
)
``` 

### Statistical Power Issues 

Our matching procedure resulted in few matched treated units: we might therefore have a low statistical power to detect the effect of cruise vessels on air pollutant concentrations. Even more worrying is our higher chance to suffer from type-S an type-M errors. While we do not know what the true effect of cruise vessels on air pollutants is, we can explore our statistical power and our probability to make type S and M errors using a set of plausible effect sizes. We proceed as follows:

* We take the standard error computed for the average treatment effect of cruise on NO2 concentration in *t* at Saint-Louis. 
* We set create a grid of plausible effect sizes.
* The `retrodesign` package allows us to compute the statistical power, the type-M and type-S errors associated with each effect size.

```{R, echo=TRUE}
# retrieve the standard error
standard_error <- data_neyman %>%
  filter(pollutant == "NO2 Saint-Louis" & time == 0) %>%
  pull(standard_error)

# create data on plausible effect sizes
data_type_m_s_errors <- tibble(plausible_effect = seq(from = 0.25, to = 6, by = 0.1))

# add the standard error to data_type_m_s_errors
data_type_m_s_errors <- data_type_m_s_errors %>%
  mutate(standard_error = standard_error)

# we compute power, type s and m errors
data_type_m_s_errors <- data_type_m_s_errors %>%
  mutate(power = map2(plausible_effect, standard_error, ~ retro_design(.x, .y)$power*100),
         type_m_error = map2(plausible_effect, standard_error, ~ retro_design(.x, .y)$typeM),
         type_s_error = map2(plausible_effect, standard_error, ~ retro_design(.x, .y)$typeS*100)) %>%
  unnest(c(power, type_m_error, type_s_error))
```

We plot and save the results:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=8, warning = FALSE, dev = "CairoPNG"}
# make the graph
graph_type_m_s_errors <- data_type_m_s_errors %>%
  rename(
    "Power (%)" = power,
    "Type M Error (Bias)" = type_m_error,
    "Type S Error (%)" = type_s_error
  ) %>%
  pivot_longer(
    cols = -c(plausible_effect, standard_error),
    names_to = "variable",
    values_to = "value"
  ) %>%
  ggplot(., aes(x = plausible_effect, y = value)) +
  geom_line(size = 1.3, colour = "deepskyblue3") +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
  facet_wrap( ~ variable, scales = "free") +
  xlab("Plausible Effect Sizes for an Average Increase\n in NO2 Concentrations (µg/m³)") + ylab("") +
  custom_theme


# print the graph
graph_type_m_s_errors

# save the graph
ggsave(
  graph_type_m_s_errors,
  filename = here::here(
    "3.outputs",
    "1.figures",
    "2.analysis_pollution",
    "1.cruise_experiment",
    "2.matching_results",
    "graph_type_m_s_errors.pdf"
  ),
  width = 40,
  height = 15,
  units = "cm",
  device = cairo_pdf
)
```

# Regression Analysis on Matching Data

Finally, we ran a simple time-stratified regression model on the matching data to see how the results differ with those found in our matched data analysis. We only adjust for calendar indicator and weather covariates measured at time t.

We first load the matching data:

```{R, echo = TRUE}
# load matching data
data_matching <- readRDS(here::here("1.data", "2.data_for_analysis", "1.cruise_experiment", "matching_data.rds")) %>%
  mutate_at(vars(is_treated, bank_day_dummy, holidays_dummy, year), ~ as.factor(.))
```

We then reshape the data:

```{R, echo = TRUE}
# reshape in long according to pollutants
data_regression_analysis <- data_matching %>%
  pivot_longer(cols = c(contains("no2"), contains("o3"), contains("pm10"), contains("pm25"), contains("so2")), names_to = "variable", values_to = "concentration") %>%
  mutate(pollutant = NA %>%
           ifelse(str_detect(variable, "no2_l"), "NO2 Longchamp",.) %>%
           ifelse(str_detect(variable, "no2_sl"), "NO2 Saint-Louis",.) %>%
           ifelse(str_detect(variable, "o3"), "O3 Longchamp",.) %>%
           ifelse(str_detect(variable, "pm10_l"), "PM10 Longchamp",.) %>%
           ifelse(str_detect(variable, "pm10_sl"), "PM10 Saint-Louis",.) %>%
           ifelse(str_detect(variable, "pm25"), "PM2.5 Longchamp",.) %>%
           ifelse(str_detect(variable, "so2"), "SO2 Lonchamp",.)) %>%
  mutate(time = 0 %>%
           ifelse(str_detect(variable, "lag_1"), -1, .) %>%
           ifelse(str_detect(variable, "lag_2"), -2, .) %>%
           ifelse(str_detect(variable, "lead_1"), 1, .) %>%
           ifelse(str_detect(variable, "lead_2"), 2, .)) %>%
  select(-variable) %>%
  select(time, is_treated, pollutant, concentration, temperature_average, rainfall_height_dummy, 
         humidity_average, wind_speed, wind_direction_categories, weekday, holidays_dummy, bank_day_dummy, month, year)
    
# we nest the data by pollutant and time
data_regression_analysis <- data_regression_analysis %>% 
  group_by(pollutant, time) %>%
  nest()
```

We run our simple model and clean the regression ouputs:

```{R, echo = TRUE}
# running the model
data_regression_analysis <- data_regression_analysis %>%
  mutate(
    # full model
    full_model = map(data, ~lm(concentration ~ is_treated + 
                                 temperature_average + I(temperature_average^2) + rainfall_height_dummy +
                                 humidity_average +
                                 wind_speed + wind_direction_categories + 
                                 weekday + holidays_dummy +
                                 bank_day_dummy + month*year, data = .)))

# transform in long according to models
data_regression_analysis <- data_regression_analysis %>%
  pivot_longer(cols = c(full_model), names_to = "model", values_to = "coefficients") %>%
  select(-data)

# tidy regression ouputs
data_regression_analysis <- data_regression_analysis %>%
  mutate(models_dfs = map(coefficients, ~ broom::tidy(.)))

# unnest results and select coefficient for total gross tonnage
data_regression_analysis <- data_regression_analysis %>%  
  unnest(models_dfs) %>%
  dplyr::filter(term=="is_treatedTRUE") %>%
  select(pollutant, time, estimate, std.error)

# we compute the 95% confidence intervals
interval_95 <- -qnorm((1-0.95)/2)

# compute lower and upper bound of each interval
data_regression_analysis <- data_regression_analysis %>%
  mutate(ci_lower_95 = estimate - std.error*interval_95,
         ci_upper_95 = estimate + std.error*interval_95)
```

We finally draw the graph of results:

```{R, echo=TRUE, layout="l-body-outset", fig.width=30, fig.height=12, warning = FALSE, dev = "CairoPNG"}
# make the graph
graph_regression_matching_data <- ggplot(data_regression_analysis, aes(x = as.factor(time), y = estimate,  ymin = ci_lower_95,
                      ymax = ci_upper_95)) +
  geom_hline(yintercept = 0, color = "black") +
  geom_vline(xintercept = "0", color = "black") +
  geom_pointrange(colour="deepskyblue3", lwd = 1.2) +
  facet_wrap(~ pollutant, scales = "free_y", ncol = 4) +
  xlab("Day") + ylab("Average Difference \nin Concentrations (µg/m³)") +
  custom_theme +
  theme(
    # axis titles parameters
    axis.title.x = element_text(size=36, face = "bold", margin = margin(t = 20, r = 0, b = 0, l =0)),
    axis.title.y = element_text(size=36, face = "bold", margin = margin(t = 0, r = 20, b = 0, l = 0)),
    # axis texts
    axis.text.x = element_text(size=20),
    axis.text.y = element_text(size=20),
    # facet texts
    strip.text.x = element_text(size=36, face = "bold"),
    strip.text.y = element_text(size=36, face = "bold"),
    # legend parameters
    legend.position = "top", legend.justification = "left", legend.direction = "horizontal",
    legend.title = element_text(size=36, face = "bold"),
    legend.text = element_text(size=28))  

# print the graph
graph_regression_matching_data

# save the graph
ggsave(graph_regression_matching_data, filename = here::here("3.outputs", "1.figures", "2.analysis_pollution", "1.cruise_experiment", "2.matching_results", "graph_regression_matching_data.pdf"), width = 70, height = 30, units = "cm", device = cairo_pdf)
```

And we display below the point estimates with the 95% confidence intervals:

```{r, echo = FALSE, layout="l-body-outset"}
data_regression_analysis %>%
  select(pollutant, time, estimate, ci_lower_95, ci_upper_95) %>%
  mutate_at(vars(estimate, ci_lower_95, ci_upper_95), ~ round(., 1)) %>%
  rename("Pollutant" = pollutant, "Time" = time, "Point Estimate" = estimate, "Lower Bound of the 95% Confidence Interval" = ci_lower_95, "Upper Bound of the 95% Confidence Interval" = ci_upper_95) %>%
  rmarkdown::paged_table(.)
````
